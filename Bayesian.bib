% Encoding: UTF-8

@Article{Webb2018,
  author    = {J. Angus Webb and Siobhan C. de Little and Kimberly A. Miller and Michael J. Stewardson},
  title     = {Quantifying and predicting the benefits of environmental flows: Combining large-scale monitoring data and expert knowledge within hierarchical Bayesian models},
  journal   = {Freshwater Biology},
  year      = {2018},
  month     = {feb},
  doi       = {10.1111/fwb.13069},
  file      = {:C\:/Users/cjdua/Documents/Webb_et_al-2018-Freshwater_Biology.pdf:PDF},
  publisher = {Wiley-Blackwell},
}

@TechReport{li2018integrated,
  author      = {Li, Yong and Yu, Jun and Zeng, Tao},
  title       = {Integrated Deviance Information Criterion for Latent Variable Models},
  institution = {Singapore Management University, School of Economics},
  year        = {2018},
  file        = {:Articles/DIC_LatentVariable25.pdf:PDF},
}

@Article{smith2002data,
  author    = {Smith, George Davey and Ebrahim, Shah},
  title     = {Data dredging, bias, or confounding: They can all get you into the BMJ and the Friday papers},
  journal   = {BMJ: British Medical Journal},
  year      = {2002},
  volume    = {325},
  number    = {7378},
  pages     = {1437},
  publisher = {BMJ Publishing Group},
}

@Article{tipping2004bayesian,
  author    = {Tipping, Michael E},
  title     = {Bayesian inference: An introduction to principles and practice in machine learning},
  journal   = {Lecture notes in computer science},
  year      = {2004},
  volume    = {3176},
  pages     = {41--62},
  publisher = {Springer},
}

@Article{wagenmakers2007practical,
  author    = {Wagenmakers, Eric-Jan},
  title     = {A practical solution to the pervasive problems ofp values},
  journal   = {Psychonomic bulletin \& review},
  year      = {2007},
  volume    = {14},
  number    = {5},
  pages     = {779--804},
  publisher = {Springer},
}

@Book{lynch2007introduction,
  title     = {Introduction to applied Bayesian statistics and estimation for social scientists},
  publisher = {Springer Science \& Business Media},
  year      = {2007},
  author    = {Lynch, Scott M},
}

@Article{scutari2009learning,
  author  = {Scutari, Marco},
  title   = {Learning Bayesian networks with the bnlearn R package},
  journal = {arXiv preprint arXiv:0908.3817},
  year    = {2009},
}

@Article{Friedman2010Regularization,
  author  = {Jerome Friedman and Trevor Hastie and Robert Tibshirani},
  title   = {Regularization Paths for Generalized Linear Models via Coordinate Descent},
  journal = {Journal of Statistical Software},
  year    = {2010},
  volume  = {33},
  number  = {1},
  pages   = {1--22},
  url     = {http://www.jstatsoft.org/v33/i01/},
}

@InBook{Sebastiani2010,
  chapter   = {10},
  pages     = {175--208},
  title     = {Bayesian Networks},
  publisher = {Springer US},
  year      = {2010},
  author    = {Sebastiani, Paola and Abad, Maria M. and Ramoni, Marco F.},
  editor    = {Maimon, Oded and Rokach, Lior},
  address   = {Boston, MA},
  isbn      = {978-0-387-09823-4},
  abstract  = {Bayesian networks are today one of the most promising approaches to Data Mining and knowledge discovery in databases. This chapter reviews the fundamental aspects of Bayesian networks and some of their technical aspects, with a particular emphasis on the methods to induce Bayesian networks from different types of data. Basic notions are illustrated through the detailed descriptions of two Bayesian network applications: one to survey data and one to marketing data.},
  booktitle = {Data Mining and Knowledge Discovery Handbook},
  doi       = {10.1007/978-0-387-09823-4_10},
  file      = {:D\:/Dropbox/Articles/[9] 2010 Data Mining and Knowledge Discovery Handbook.pdf:PDF},
  url       = {https://doi.org/10.1007/978-0-387-09823-4_10},
}

@Article{Simon2011Coxnet,
  author  = {Noah Simon and Jerome Friedman and Trevor Hastie and Rob Tibshirani},
  title   = {Regularization Paths for Cox's Proportional Hazards Model via Coordinate Descent},
  journal = {Journal of Statistical Software},
  year    = {2011},
  volume  = {39},
  number  = {5},
  pages   = {1--13},
  url     = {http://www.jstatsoft.org/v39/i05/},
}

@Article{dienes2011bayesian,
  author    = {Dienes, Zoltan},
  title     = {Bayesian versus orthodox statistics: Which side are you on?},
  journal   = {Perspectives on Psychological Science},
  year      = {2011},
  volume    = {6},
  number    = {3},
  pages     = {274--290},
  publisher = {Sage Publications Sage CA: Los Angeles, CA},
}

@Misc{etz2016using,
  author    = {Etz, Alexander},
  title     = {Using Bayes Factors to Get the Most Out of Linear Regression: a Practical Guide Using R},
  year      = {2016},
  publisher = {Citeseer},
}

@Article{benjamin2017redefine,
  author  = {Benjamin, Daniel J and Berger, James O and Johannesson, Magnus and Nosek, Brian A and Wagenmakers, Eric-Jan and Berk, Richard and Bollen, Kenneth A and Brembs, Bj{\"o}rn and Brown, Lawrence and Camerer, Colin and others},
  title   = {Redefine statistical significance},
  journal = {Nature Human Behaviour},
  year    = {2017},
}

@Article{lobo2011short,
  author    = {Lobo, Miguel Sousa},
  title     = {A Short JAGS Tutorial with an Interpersonal Perception/Social Network Example},
  year      = {2011},
  file      = {:C\:/Users/cjdua/Documents/JAGS_tutorial_Lobo.pdf:PDF},
  publisher = {Citeseer},
}

@InProceedings{zhang2018fairness,
  author    = {Zhang, Junzhe and Bareinboim, Elias},
  title     = {Fairness in Decision-Making--The Causal Explanation Formula},
  booktitle = {Proceedings of the 32nd AAAI Conference on Artificial Intelligence},
  year      = {2018},
  doi       = {10.1155/2018/5176920},
  file      = {:C\:/Users/cjdua/Documents/r30.pdf:PDF},
}

@Article{gelman2017stents,
  author = {Gelman, Andrew and Nallamothu, Brahmajee},
  title  = {Stents: An exploration of design, measurement, analysis, and reporting in clinical research},
  year   = {2017},
  file   = {:C\:/Users/cjdua/Documents/Stent An exploration of design measurement analysis and reporting in.pdf:PDF},
}

@Article{trangucci2018voting,
  author  = {Trangucci, Rob and Ali, Imad and Gelman, Andrew and Rivers, Doug},
  title   = {Voting patterns in 2016: Exploration using multilevel regression and poststratification (MRP) on pre-election polls},
  journal = {arXiv preprint arXiv:1802.00842},
  year    = {2018},
  file    = {:C\:/Users/cjdua/Documents/1802.00842.pdf:PDF},
}

@Article{McShane2017,
  author    = {Blakeley B. McShane and David Gal},
  title     = {Statistical Significance and the Dichotomization of Evidence},
  journal   = {Journal of the American Statistical Association},
  year      = {2017},
  volume    = {112},
  number    = {519},
  pages     = {885--895},
  month     = {jul},
  abstract  = {In light of recent concerns about reproducibility and replicability, the ASA issued a Statement on Statistical Significance and p-values aimed at those who are not primarily statisticians. While the ASA Statement notes that statistical significance and p-values are “commonly misused and misinterpreted,” it does not discuss and document broader implications of these errors for the interpretation of evidence. In this article, we review research on how applied researchers who are not primarily statisticians misuse and misinterpret p-values in practice and how this can lead to errors in the interpretation of evidence. We also present new data showing, perhaps surprisingly, that researchers who are primarily statisticians are also prone to misuse and misinterpret p-values thus resulting in similar errors. In particular, we show that statisticians tend to interpret evidence dichotomously based on whether or not a p-value crosses the conventional 0.05 threshold for statistical significance. We discuss implications and offer recommendations.

KEYWORDS: Null hypothesis significance testing, p-value, Statistical significance, Sociology of science},
  doi       = {10.1080/01621459.2017.1289846},
  file      = {:Articles/Statistical Significance and the Dichotomization of Evidence.pdf:PDF},
  publisher = {Informa {UK} Limited},
}

@Article{Woltman2012,
  author    = {Heather Woltman and Andrea Feldstain and J. Christine MacKay and Meredith Rocchi},
  title     = {An introduction to hierarchical linear modeling},
  journal   = {Tutorials in Quantitative Methods for Psychology},
  year      = {2012},
  volume    = {8},
  number    = {1},
  pages     = {52--69},
  month     = {feb},
  abstract  = {This tutorial aims to introduce Hierarchical Linear Modeling (HLM). A simple explanation of HLM is provided that describes when to use this statistical technique and identifies key factors to consider before conducting this analysis. The first section of the tutorial defines HLM, clarifies its purpose, and states its advantages. The second section explains the mathematical theory, equations, and conditions underlying HLM. HLM hypothesis testing is performed in the third section. Finally, the fourth section provides a practical example of running HLM, with which readers can follow along. Throughout this tutorial, emphasis is placed on providing a straightforward overview of the basic principles of HLM.},
  doi       = {10.20982/tqmp.08.1.p052},
  file      = {:D\:/Github/Informs/Articles/p052.pdf:PDF;:C\:/Users/cjdua/Downloads/p052.zip:zip},
  publisher = {The Quantitative Methods for Psychology},
}

@Article{Song2012,
  author    = {Xin-Yuan Song and Sik-Yum Lee},
  title     = {A tutorial on the Bayesian approach for analyzing structural equation models},
  journal   = {Journal of Mathematical Psychology},
  year      = {2012},
  volume    = {56},
  number    = {3},
  pages     = {135--148},
  month     = {jun},
  abstract  = {In this paper, we provide a tutorial exposition on the Bayesian approach in analyzing structural equation models (SEMs). SEMs, which can be regarded as regression models with observed and latent variables, have been widely applied to substantive research. However, the classical methods and most commercial software in this area are based on the covariance structure approach, which would encounter serious difficulties when dealing with complicated models and/or data structures. In contrast, the Bayesian approach has much more flexibility in handling complex situations. We give a brief introduction to SEMs and a detailed description of how to apply the Bayesian approach to this kind of model. Advantages of the Bayesian approach are discussed, and results obtained from a simulation study are provided for illustration. The intended audience is statisticians/methodologists who either know about SEMs or simple Bayesian statistics, and Ph.D. students in statistics, psychometrics, or mathematical psychology.},
  doi       = {10.1016/j.jmp.2012.02.001},
  file      = {:D\:/Github/Informs/Articles/Tutorial_Bayesian_SEM.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{jones2018network,
  author    = {Jones, Payton J and Mair, Patrick and Riemann, Bradley C and Mugno, Beth L and McNally, Richard J},
  title     = {A network perspective on comorbid depression in adolescents with obsessive-compulsive disorder},
  journal   = {Journal of anxiety disorders},
  year      = {2018},
  volume    = {53},
  pages     = {1--8},
  file      = {:Articles/A Network Perspective on Comorbid Depression.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Chao2017,
  author    = {Yi-Sheng Chao and Hau-tieng Wu and Marco Scutari and Tai-Shen Chen and Chao-Jung Wu and Madeleine Durand and Antoine Boivin},
  title     = {A network perspective on patient experiences and health status: the Medical Expenditure Panel Survey 2004 to 2011},
  journal   = {{BMC} Health Services Research},
  year      = {2017},
  volume    = {17},
  number    = {1},
  month     = {aug},
  doi       = {10.1186/s12913-017-2496-5},
  file      = {:Articles/10.1186.s12913-017-2496-5.pdf:PDF},
  publisher = {Springer Nature},
}

@Article{McNally2017,
  author    = {R. J. McNally and P. Mair and B. L. Mugno and B. C. Riemann},
  title     = {Co-morbid obsessive{\textendash}compulsive disorder and depression: a Bayesian network approach},
  journal   = {Psychological Medicine},
  year      = {2017},
  volume    = {47},
  number    = {07},
  pages     = {1204--1214},
  month     = {jan},
  doi       = {10.1017/s0033291716003287},
  file      = {:Articles/McNally-Mair-Mugno-Riemann-in-press-Psychological-Medicine.pdf:PDF},
  publisher = {Cambridge University Press ({CUP})},
}

@Article{liu2018bus,
  author    = {Liu, Yi and Jia, Yuanhua and Feng, Xuesong and Wu, Jiang},
  title     = {Bus Route Design with a Bayesian Network Analysis of Bus Service Revenues},
  journal   = {Mathematical Problems in Engineering},
  year      = {2018},
  volume    = {2018},
  file      = {:Articles/2018. Bus Route.pdf:PDF},
  publisher = {Hindawi},
}

@Article{Deng2014,
  author    = {Li Deng},
  title     = {Deep Learning: Methods and Applications},
  journal   = {Foundations and Trends{\textregistered} in Signal Processing},
  year      = {2014},
  volume    = {7},
  number    = {3-4},
  pages     = {197--387},
  doi       = {10.1561/2000000039},
  file      = {:Articles/9781601988157-summary.pdf:PDF},
  publisher = {Now Publishers},
}

@Article{team2015stan,
  author  = {Team, Stan Developers},
  title   = {Stan Modeling Language: User’s Guide and Reference Manual},
  journal = {Version 2.12},
  year    = {2015},
}

@Article{Overstall2018,
  author      = {Antony M. Overstall and James M. McGree},
  title       = {Bayesian design of experiments for intractable likelihood models using coupled auxiliary models and multivariate emulation},
  abstract    = {A Bayesian design is given by maximising the expected utility over the design space. The utility is chosen to represent the aim of the experiment and its expectation is taken with respect to all unknowns: responses, parameters and/or models. Although straightforward in principle, there are several challenges to finding Bayesian designs in practice. Firstly, the expected utility is rarely available in closed form and requires approximation. Secondly, the expected utility needs to be maximised over a, potentially, high-dimensional design space. In the case of intractable likelihood models, these problems are compounded by the fact that the likelihood function, whose evaluation is required to approximate the expected utility, is not available in closed form. A strategy is proposed to find Bayesian designs for intractable likelihood models. It relies on the development of new methodology involving auxiliary modelling to approximate the expected utility, under an intractable likelihood model, applied with the latest approaches to maximising approximated expected utilities.},
  date        = {2018-03-19},
  eprint      = {1803.07018v1},
  eprintclass = {stat.ME},
  eprinttype  = {arXiv},
  file        = {:Articles/2018.arXiv.1803.07018.pdf:PDF},
  keywords    = {stat.ME},
}

@Article{Lakens2017,
  author  = {Lakens, D and Adolfi, FG and Albers, CJ and Anvari, F and Apps, MAJ and Argamon, SE and Zwaan, RA},
  title   = {Justify your alpha: A response to “Redefine statistical significance”},
  journal = {Retrieved from psyarxiv. com/9s3y6},
  year    = {2017},
  file    = {:D\:/Dropbox/Bayes_Reading/Justify Your Alpha.pdf:PDF},
}

@InProceedings{Dash2003,
  author       = {Dash, Denver and Cooper, Gregory F},
  title        = {Model-Averaging with Discrete Bayesian Network Classifiers},
  booktitle    = {Proc. 9th Int. Workshop Artif. Intell. Statist.},
  year         = {2003},
  pages        = {38--45},
  organization = {Citeseer},
  file         = {:C\:/Users/cjdua/Documents/download.pdf:PDF},
}

@Article{Amrhein2017,
  author    = {Valentin Amrhein and Sander Greenland},
  title     = {Remove, rather than redefine, statistical significance},
  journal   = {Nature Human Behaviour},
  year      = {2017},
  volume    = {2},
  number    = {1},
  pages     = {4--4},
  month     = {sep},
  doi       = {10.1038/s41562-017-0224-0},
  file      = {:Articles/2017.Nature_Human_Behaviour.pdf:PDF},
  publisher = {Springer Nature},
}

@Misc{,
  author = {{Stan Development Team}},
  title  = {shinystan: Interactive Visual and Numerical Diagnostics and Posterior Analysis for Bayesian Models.},
  year   = {2017},
  note   = {R package version 2.4.0},
  url    = {http://mc-stan.org/},
}

@Article{Williams2018,
  author    = {Daniel Williams},
  title     = {Predictive coding and thought},
  journal   = {Synthese},
  year      = {2018},
  month     = {mar},
  doi       = {10.1007/s11229-018-1768-x},
  file      = {:Articles/2018.Synthese.10.1007s11229-0181768-x.pdf:PDF},
  publisher = {Springer Nature},
}

@Article{Deaton2017,
  author    = {Angus Deaton and Nancy Cartwright},
  title     = {Understanding and misunderstanding randomized controlled trials},
  journal   = {Social Science {\&} Medicine},
  year      = {2017},
  month     = {dec},
  doi       = {10.1016/j.socscimed.2017.12.005},
  file      = {:Articles/1-s2.0-S0277953617307359-main.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Li2018,
  author    = {Shaobo Li and Yongming Wu and Yanxia Xu and Jie Hu and Jianjun Hu},
  title     = {A Bayesian Network Based Adaptability Design of Product Structures for Function Evolution},
  journal   = {Applied Sciences},
  year      = {2018},
  volume    = {8},
  number    = {4},
  pages     = {493},
  month     = {mar},
  doi       = {10.3390/app8040493},
  file      = {:Articles/applsci-08-00493.pdf:PDF},
  publisher = {{MDPI} {AG}},
}

@Article{Chiappa2018,
  author      = {Silvia Chiappa and Thomas P. S. Gillam},
  title       = {Path-Specific Counterfactual Fairness},
  abstract    = {We consider the problem of learning fair decision systems in complex scenarios in which a sensitive attribute might affect the decision along both fair and unfair pathways. We introduce a causal approach to disregard effects along unfair pathways that simplifies and generalizes previous literature. Our method corrects observations adversely affected by the sensitive attribute, and uses these to form a decision. This avoids disregarding fair information, and does not require an often intractable computation of the path-specific effect. We leverage recent developments in deep learning and approximate inference to achieve a solution that is widely applicable to complex, non-linear scenarios.},
  date        = {2018-02-22},
  eprint      = {1802.08139v1},
  eprintclass = {stat.ML},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1802.08139v1:PDF;:Articles/1802.08139.pdf:PDF},
  keywords    = {stat.ML},
}

@InProceedings{bareinboim2018,
  author    = {J. Zhang, E. Bareinboim},
  title     = {Fairness in Decision-Making -- The Causal Explanation Formula},
  booktitle = {Proceedings of the 32nd AAAI Conference on Artificial Intelligence},
  year      = {2018},
  file      = {:Articles/r30.pdf:PDF},
}

@Article{Chen238998,
  author    = {Gang Chen and Yaqiong Xiao and Paul A Taylor and Justin K Rajendra and Tracy Riggins and Fengji Geng and Elizabeth Redcay and Robert W Cox},
  title     = {Handling Multiplicity in Neuroimaging through Bayesian Lenses with Multilevel Modeling},
  journal   = {bioRxiv preprint},
  year      = {2017},
  month     = {dec},
  abstract  = {In neuroimaging, the multiplicity issue may sneak into data analysis through several channels, affecting
expected false positive rates (FPRs; type I errors) in diverse ways. One widely recognized aspect of multiplicity,
multiple testing, occurs when the investigator fits a separate model for each voxel in the brain. However,
multiplicity also occurs when the investigator conducts multiple comparisons within a model, tests two tails of
a t-test separately when prior information is unavailable about the directionality, and branches in the analytic
pipelines. The current practice of handling multiple testing through controlling the overall FPR in neuroimaging
under the null hypothesis significance testing (NHST) paradigm excessively penalizes the statistical power with
inflated type II errors. More fundamentally, the adoption of dichotomous decisions through sharp thresholding
under NHST may not be appropriate when the null hypothesis itself is not pragmatically relevant because the
effect of interest takes a continuum instead of discrete values and is not expected to be null in most brain regions.
When the noise inundates the signal, two different types of error are more relevant than the concept of FPR:
incorrect sign (type S) and incorrect magnitude (type M).
In light of these considerations, we introduce a different strategy using Bayesian hierarchical modeling (BHM)
to achieve two goals: 1) improving modeling efficiency via one integrative (instead of many separate) model and
dissolving the multiple testing issue, and 2) turning the focus of conventional NHST on FPR into quality control
by calibrating type S errors while maintaining a reasonable level of inference efficiency. The performance and
validity of this approach are demonstrated through an application at the region of interest (ROI) level, with all
the regions on an equal footing: unlike the current approaches under NHST, small regions are not disadvantaged
simply because of their physical size. In addition, compared to the massively univariate approach, BHM may
simultaneously achieve increased spatial specificity and inference efficiency. The benefits of BHM are illustrated in
model performance and quality checking using an experimental dataset. In addition, BHM offers an alternative,
confirmatory, or complementary approach to the conventional whole brain analysis under NHST, and promotes
results reporting in totality and transparency. The methodology also avoids sharp and arbitrary thresholding in
the p-value funnel to which the multidimensional data are reduced. The modeling approach with its auxiliary
tools will be available as part of the AFNI suite for general use.},
  doi       = {10.1101/238998},
  file      = {:Articles/238998.full.pdf:PDF},
  publisher = {Cold Spring Harbor Laboratory},
}

@Article{Romeijn2018,
  author    = {Jan-Willem Romeijn and Jon Williamson},
  title     = {Intervention and Identifiability in Latent Variable Modelling},
  journal   = {Minds and Machines},
  year      = {2018},
  month     = {mar},
  doi       = {10.1007/s11023-018-9460-y},
  file      = {:Articles/10.1007%2Fs11023-018-9460-y.pdf:PDF},
  publisher = {Springer Nature},
}

@Article{Hoffman2014,
  author  = {Hoffman, Matthew D and Gelman, Andrew},
  title   = {The No-U-turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo.},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {1},
  pages   = {1593--1623},
}

@Article{Weber2016,
  author  = {Weber, Sebastian and Gelman, Andrew and Carpenter, Bob and Lee, Daniel and Betancourt, Michael and Vehtari, Aki and Racine, Amy},
  title   = {Hierarchical expectation propagation for Bayesian aggregation of average data},
  journal = {arXiv preprint arXiv:1602.02055},
  year    = {2016},
  file    = {:Articles/1602.02055.pdf:PDF},
}

@Article{Liu2016,
  author    = {G. Frank Liu and Baoguang Han and Xin Zhao and Qun Lin},
  title     = {A Comparison of Frequentist and Bayesian Model Based Approaches for~Missing Data Analysis: Case Study with a Schizophrenia Clinical Trial},
  journal   = {Statistics in Biopharmaceutical Research},
  year      = {2016},
  volume    = {8},
  number    = {1},
  pages     = {116--127},
  month     = {jan},
  abstract  = {Missing data are common in clinical trials and could lead to biased estimation of treatment effects. The National Research Council (NRC) report suggests that sensitivity analysis on missing data mechanism should be a mandatory component of the primary reporting of findings from clinical trials, and regulatory agencies are requesting more thorough sensitivity analyses from sponsors. However, recent literature research showed that missing data were almost always inadequately handled. This is partially due to the lack of standard software packages and straightforward implementation platform. With recent availability of flexible Bayesian software packages such as WinBUGS, SAS Proc MCMC, and Stan, it is relatively simple to develop Bayesian methods to address complex missing data problems while incorporating the uncertainty. In this article, we present a case study from the DIA Bayesian Scientific Working Group (BSWG) on Bayesian approaches for missing data analysis. We illustrate how to use Bayesian approaches to fit a few commonly used frequentist missing data models. The properties, advantage, and flexibility of the Bayesian analysis methods will be discussed using a case study based on a schizophrenia clinical trial. Supplementary materials for this article are available online.

Key Words: Bayesian, Longitudinal clinical trial, Missing data, Sensitivity analysis},
  doi       = {10.1080/19466315.2015.1077725},
  publisher = {Informa {UK} Limited},
}

@Article{Buerkner2016,
  author   = {B{\"u}rkner, Paul-Christian and others},
  title    = {brms: An R package for Bayesian multilevel models using Stan},
  journal  = {Journal of Statistical Software},
  year     = {2016},
  volume   = {80},
  number   = {1},
  pages    = {1--28},
  abstract = {The brms package implements Bayesian multilevel models in R using the probabilistic
programming language Stan. A wide range of distributions and link functions are
supported, allowing users to fit – among others – linear, robust linear, binomial, Poisson,
survival, response times, ordinal, quantile, zero-inflated, hurdle, and even non-linear
models all in a multilevel context. Further modeling options include autocorrelation of
the response variable, user defined covariance structures, censored data, as well as metaanalytic
standard errors. Prior specifications are flexible and explicitly encourage users
to apply prior distributions that actually reflect their beliefs. In addition, model fit can
easily be assessed and compared using posterior-predictive checks and leave-one-out crossvalidation.
If you use the software, please cite this article as published in the Journal of
Statistical Software Burkner ¨ (2017).
Keywords: Bayesian inference, multilevel model, ordinal data, MCMC, Stan, R.},
  file     = {:Articles/brms_overview.pdf:PDF},
}

@Article{Carpenter2016,
  author  = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matt and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Michael A and Guo, Jiqiang and Li, Peter and Riddell, Allen and others},
  title   = {Stan: A probabilistic programming language},
  journal = {Journal of Statistical Software},
  year    = {2016},
  volume  = {20},
  number  = {2},
  pages   = {1--37},
  file    = {:Articles/Stan - Probabilistic Programming Language.pdf:PDF},
}

@Article{Gelman2015,
  author    = {Gelman, Andrew and Lee, Daniel and Guo, Jiqiang},
  title     = {Stan: A probabilistic programming language for Bayesian inference and optimization},
  journal   = {Journal of Educational and Behavioral Statistics},
  year      = {2015},
  volume    = {40},
  number    = {5},
  pages     = {530--543},
  publisher = {SAGE Publications Sage CA: Los Angeles, CA},
}

@Article{Lopez2018,
  author    = {Romain Lopez and Jeffrey Regier and Michael B Cole and Michael Jordan and Nir Yosef},
  title     = {Bayesian Inference for a Generative Model of Transcriptome Profiles from Single-cell {RNA} Sequencing},
  journal   = {bioRxiv},
  year      = {2018},
  month     = {mar},
  abstract  = {Transcriptome profiles of individual cells reflect true and often unexplored biological diversity, but are also affected by noise of biological and technical nature. This raises the need to explicitly model the resulting uncertainty and take it into account in any downstream analysis, such as dimensionality reduction, clustering, and differential expression. Here, we introduce Single-cell Variational Inference (scVI), a scalable framework for probabilistic representation and analysis of gene expression in single cells. Our model uses variational inference and stochastic optimization of deep neural networks to approximate the parameters that govern the distribution of expression values of each gene in every cell, using a non-linear mapping between the observations and a low-dimensional latent space. By doing so, scVI pools information between similar cells or genes while taking nuisance factors of variation such as batch effects and limited sensitivity into account. To evaluate scVI, we conducted a comprehensive comparative analysis to existing methods for distributional modeling and dimensionality reduction, all of which rely on generalized linear models. We first show that scVI scales to over one million cells, whereas competing algorithms can process at most tens of thousands of cells. Next, we show that scVI fits unseen data more closely and can impute missing data more accurately, both indicative of a better generalization capacity. We then utilize scVI to conduct a set of fundamental analysis tasks -- including batch correction, visualization, clustering and differential expression -- and demonstrate its accuracy in comparison to the state-of-the-art tools in each task. scVI is publicly available, and can be readily used as a principled and inclusive solution for multiple tasks of single-cell RNA sequencing data analysis.},
  doi       = {10.1101/292037},
  file      = {:Articles/292037.full.pdf:PDF},
  publisher = {Cold Spring Harbor Laboratory},
}

@Article{Kruschke2010,
  author    = {John K. Kruschke},
  title     = {Bayesian data analysis},
  journal   = {Wiley Interdisciplinary Reviews: Cognitive Science},
  year      = {2010},
  volume    = {1},
  number    = {5},
  pages     = {658--676},
  month     = {apr},
  doi       = {10.1002/wcs.72},
  publisher = {Wiley-Blackwell},
}

@Book{Gelman2014,
  title     = {Bayesian data analysis},
  publisher = {CRC press Boca Raton, FL},
  year      = {2014},
  author    = {Gelman, Andrew and Carlin, John B and Stern, Hal S and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
  volume    = {2},
}

@Article{Mitchell2018,
  author    = {Shira Mitchell and Andrew Gelman and Rebecca Ross and Joyce Chen and Sehrish Bari and Uyen Kim Huynh and Matthew W Harris and Sonia Ehrlich Sachs and Elizabeth A Stuart and Avi Feller and Susanna Makela and Alan M Zaslavsky and Lucy McClellan and Seth Ohemeng-Dapaah and Patricia Namakula and Cheryl A Palm and Jeffrey D Sachs},
  title     = {The Millennium Villages Project: a retrospective, observational, endline evaluation},
  journal   = {The Lancet Global Health},
  year      = {2018},
  volume    = {6},
  number    = {5},
  pages     = {e500--e513},
  month     = {may},
  doi       = {10.1016/s2214-109x(18)30065-2},
  file      = {:Articles/PIIS2214109X18300652.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Merkle2016,
  author    = {Edgar C. Merkle and Ting Wang},
  title     = {Bayesian latent variable models for the analysis of experimental psychology data},
  journal   = {Psychonomic Bulletin {\&} Review},
  year      = {2016},
  volume    = {25},
  number    = {1},
  pages     = {256--270},
  month     = {mar},
  doi       = {10.3758/s13423-016-1016-7},
  file      = {:Articles/10.3758_s13423-016-1016-7[2155].pdf:PDF},
  publisher = {Springer Nature},
}

@Article{Kruschke2017,
  author    = {John K. Kruschke and Torrin M. Liddell},
  title     = {Bayesian data analysis for newcomers},
  journal   = {Psychonomic Bulletin {\&} Review},
  year      = {2017},
  volume    = {25},
  number    = {1},
  pages     = {155--177},
  month     = {apr},
  doi       = {10.3758/s13423-017-1272-1},
  file      = {:Articles/10.3758_s13423-017-1272-1[2156].pdf:PDF},
  publisher = {Springer Nature},
}

@Article{Kruschke2017a,
  author    = {John K. Kruschke and Torrin M. Liddell},
  title     = {The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective},
  journal   = {Psychonomic Bulletin {\&} Review},
  year      = {2017},
  volume    = {25},
  number    = {1},
  pages     = {178--206},
  month     = {feb},
  doi       = {10.3758/s13423-016-1221-4},
  file      = {:Articles/10.3758_s13423-016-1221-4[2157].pdf:PDF},
  publisher = {Springer Nature},
}

@Article{Oravecz2017,
  author    = {Zita Oravecz and Chelsea Muth},
  title     = {Fitting growth curve models in the Bayesian framework},
  journal   = {Psychonomic Bulletin {\&} Review},
  year      = {2017},
  volume    = {25},
  number    = {1},
  pages     = {235--255},
  month     = {may},
  doi       = {10.3758/s13423-017-1281-0},
  file      = {:D\:/Dropbox/Bayes_Reading/File Apr 15, 7 38 21 PM.pdf:PDF},
  publisher = {Springer Nature},
}

@Article{Dienes2017,
  author    = {Zoltan Dienes and Neil Mclatchie},
  title     = {Four reasons to prefer Bayesian analyses over significance testing},
  journal   = {Psychonomic Bulletin {\&} Review},
  year      = {2017},
  volume    = {25},
  number    = {1},
  pages     = {207--218},
  month     = {mar},
  doi       = {10.3758/s13423-017-1266-z},
  file      = {:Articles/10.3758%2Fs13423-017-1266-z.pdf:PDF},
  publisher = {Springer Nature},
}

@Article{Wagenmakers2017,
  author    = {Eric-Jan Wagenmakers and Maarten Marsman and Tahira Jamil and Alexander Ly and Josine Verhagen and Jonathon Love and Ravi Selker and Quentin F. Gronau and Martin {\v{S}}m{\'{\i}}ra and Sacha Epskamp and Dora Matzke and Jeffrey N. Rouder and Richard D. Morey},
  title     = {Bayesian inference for psychology. Part I: Theoretical advantages and practical ramifications},
  journal   = {Psychonomic Bulletin {\&} Review},
  year      = {2017},
  volume    = {25},
  number    = {1},
  pages     = {35--57},
  month     = {aug},
  doi       = {10.3758/s13423-017-1343-3},
  file      = {:Articles/10.3758%2Fs13423-017-1343-3.pdf:PDF},
  publisher = {Springer Nature},
}

@Article{Wagenmakers2017a,
  author    = {Eric-Jan Wagenmakers and Jonathon Love and Maarten Marsman and Tahira Jamil and Alexander Ly and Josine Verhagen and Ravi Selker and Quentin F. Gronau and Damian Dropmann and Bruno Boutin and Frans Meerhoff and Patrick Knight and Akash Raj and Erik-Jan van Kesteren and Johnny van Doorn and Martin {\v{S}}m{\'{\i}}ra and Sacha Epskamp and Alexander Etz and Dora Matzke and Tim de Jong and Don van den Bergh and Alexandra Sarafoglou and Helen Steingroever and Koen Derks and Jeffrey N. Rouder and Richard D. Morey},
  title     = {Bayesian inference for psychology. Part {II}: Example applications with {JASP}},
  journal   = {Psychonomic Bulletin {\&} Review},
  year      = {2017},
  volume    = {25},
  number    = {1},
  pages     = {58--76},
  month     = {jul},
  doi       = {10.3758/s13423-017-1323-7},
  file      = {:Articles/10.3758%2Fs13423-017-1323-7.pdf:PDF},
  publisher = {Springer Nature},
}

@Article{Matzke2018,
  author   = {Matzke, Dora and Boehm, Udo and Vandekerckhove, Joachim},
  title    = {Bayesian inference for psychology, part III: Parameter estimation in nonstandard models},
  journal  = {Psychonomic Bulletin {\&} Review},
  year     = {2018},
  volume   = {25},
  number   = {1},
  pages    = {77--101},
  month    = {Feb},
  issn     = {1531-5320},
  abstract = {We demonstrate the use of three popular Bayesian software packages that enable researchers to estimate parameters in a broad class of models that are commonly used in psychological research. We focus on WinBUGS, JAGS, and Stan, and show how they can be interfaced from R and MATLAB. We illustrate the use of the packages through two fully worked examples; the examples involve a simple univariate linear regression and fitting a multinomial processing tree model to data from a classic false-memory experiment. We conclude with a comparison of the strengths and weaknesses of the packages. Our example code, data, and this text are available via                   https://osf.io/ucmaz/                                  .},
  day      = {01},
  doi      = {10.3758/s13423-017-1394-5},
  file     = {:D\:/Dropbox/Bayes_Reading/File Apr 15, 7 40 34 PM.pdf:PDF},
  url      = {https://doi.org/10.3758/s13423-017-1394-5},
}

@Article{Rouder2018,
  author   = {Rouder, Jeffrey N. and Haaf, Julia M. and Vandekerckhove, Joachim},
  title    = {Bayesian inference for psychology, part IV: parameter estimation and Bayes factors},
  journal  = {Psychonomic Bulletin {\&} Review},
  year     = {2018},
  volume   = {25},
  number   = {1},
  pages    = {102--113},
  month    = {Feb},
  issn     = {1531-5320},
  abstract = {In the psychological literature, there are two seemingly different approaches to inference: that from estimation of posterior intervals and that from Bayes factors. We provide an overview of each method and show that a salient difference is the choice of models. The two approaches as commonly practiced can be unified with a certain model specification, now popular in the statistics literature, called spike-and-slab priors. A spike-and-slab prior is a mixture of a null model, the spike, with an effect model, the slab. The estimate of the effect size here is a function of the Bayes factor, showing that estimation and model comparison can be unified. The salient difference is that common Bayes factor approaches provide for privileged consideration of theoretically useful parameter values, such as the value corresponding to the null hypothesis, while estimation approaches do not. Both approaches, either privileging the null or not, are useful depending on the goals of the analyst.},
  day      = {01},
  doi      = {10.3758/s13423-017-1420-7},
  file     = {:D\:/Dropbox/Bayes_Reading/10.3758s13423-017-1420-7.pdf:PDF},
  url      = {https://doi.org/10.3758/s13423-017-1420-7},
}

@Article{Lee2018,
  author   = {Lee, Michael D. and Vanpaemel, Wolf},
  title    = {Determining informative priors for cognitive models},
  journal  = {Psychonomic Bulletin {\&} Review},
  year     = {2018},
  volume   = {25},
  number   = {1},
  pages    = {114--127},
  month    = {Feb},
  issn     = {1531-5320},
  abstract = {The development of cognitive models involves the creative scientific formalization of assumptions, based on theory, observation, and other relevant information. In the Bayesian approach to implementing, testing, and using cognitive models, assumptions can influence both the likelihood function of the model, usually corresponding to assumptions about psychological processes, and the prior distribution over model parameters, usually corresponding to assumptions about the psychological variables that influence those processes. The specification of the prior is unique to the Bayesian context, but often raises concerns that lead to the use of vague or non-informative priors in cognitive modeling. Sometimes the concerns stem from philosophical objections, but more often practical difficulties with how priors should be determined are the stumbling block. We survey several sources of information that can help to specify priors for cognitive models, discuss some of the methods by which this information can be formalized in a prior distribution, and identify a number of benefits of including informative priors in cognitive modeling. Our discussion is based on three illustrative cognitive models, involving memory retention, categorization, and decision making.},
  day      = {01},
  doi      = {10.3758/s13423-017-1238-3},
  file     = {:Articles/10.3758%2Fs13423-017-1238-3.pdf:PDF},
  url      = {https://doi.org/10.3758/s13423-017-1238-3},
}

@Article{Kaplan2018,
  author    = {David Kaplan and Chansoon Lee},
  title     = {Optimizing Prediction Using Bayesian Model Averaging: Examples Using Large-Scale Educational Assessments},
  journal   = {Evaluation Review},
  year      = {2018},
  pages     = {0193841X1876142},
  month     = {apr},
  abstract  = {This article provides a review of Bayesian model averaging as a means of optimizing the predictive performance of common statistical models applied to large-scale educational assessments. The Bayesian framework recognizes that in addition to parameter uncertainty, there is uncertainty in the choice of models themselves. A Bayesian approach to addressing the problem of model uncertainty is the method of Bayesian model averaging. Bayesian model averaging searches the space of possible models for a set of submodels that satisfy certain scientific principles and then averages the coefficients across these submodels weighted by each model’s posterior model probability (PMP). Using the weighted coefficients for prediction has been shown to yield optimal predictive performance according to certain scoring rules. We demonstrate the utility of Bayesian model averaging for prediction in education research with three examples: Bayesian regression analysis, Bayesian logistic regression, and a recently developed approach for Bayesian structural equation modeling. In each case, the model-averaged estimates are shown to yield better prediction of the outcome of interest than any submodel based on predictive coverage and the log-score rule. Implications for the design of large-scale assessments when the goal is optimal prediction in a policy context are discussed.

Keywords Bayesian model averaging, large-scale assessments, education},
  doi       = {10.1177/0193841x18761421},
  file      = {:Articles/0193841x18761421[2197].pdf:PDF},
  publisher = {{SAGE} Publications},
}

@Article{Kaplan2016,
  author    = {David Kaplan},
  title     = {Causal inference with large-scale assessments in education from a Bayesian perspective: a review and synthesis},
  journal   = {Large-scale Assessments in Education},
  year      = {2016},
  volume    = {4},
  number    = {1},
  month     = {may},
  doi       = {10.1186/s40536-016-0022-6},
  file      = {:Articles/10.1186%2Fs40536-016-0022-6.pdf:PDF},
  publisher = {Springer Nature},
}

@Article{Gelman1996,
  author        = {Gelman, Andrew and Meng, Xiao-Li and Stern, Hal},
  title         = {Posterior predictive assessment of model fitness via realized discrepancies},
  journal       = {Statistica sinica},
  year          = {1996},
  pages         = {733--760},
  __markedentry = {[dulunche:]},
  publisher     = {JSTOR},
}

@Article{Merkle2018,
  author        = {E. C. Merkle and D. Furr and S. Rabe-Hesketh},
  title         = {Bayesian model assessment: Use of conditional vs marginal likelihoods},
  __markedentry = {[dulunche:6]},
  abstract      = {Typical Bayesian methods for models with latent variables (or random effects) involve directly sampling the latent variables along with the model parameters. In high-level software code for model definitions (using, e.g., BUGS, JAGS, Stan), the likelihood is therefore specified as conditional on the latent variables. This can lead researchers to perform model comparisons via conditional likelihoods, where the latent variables are considered model parameters. In other settings, typical model comparisons involve marginal likelihoods where the latent variables are integrated out. This distinction is often overlooked despite the fact that it can have a large impact on the comparisons of interest. In this paper, we clarify and illustrate these issues, focusing on the comparison of conditional and marginal Deviance Information Criteria (DICs) and Watanabe-Akaike Information Criteria (WAICs) in psychometric modeling. The conditional/marginal distinction corresponds to whether the model should be predictive for the clusters that are in the data or for new clusters (where "clusters" typically correspond to higher-level units like people or schools). Correspondingly, we show that marginal WAIC corresponds to leave-one-cluster out (LOcO) cross-validation, whereas conditional WAIC corresponds to leave-one-unit (LOuO). These results lead to recommendations on the general application of these criteria to models with latent variables.},
  date          = {2018-02-13},
  eprint        = {1802.04452v1},
  eprintclass   = {stat.CO},
  eprinttype    = {arXiv},
  file          = {:Articles/1802.04452.pdf:PDF},
  keywords      = {stat.CO},
}

@Article{Wiedermann2018,
  author    = {Wolfgang Wiedermann and Xintong Li},
  title     = {Direction dependence analysis: A framework to test the direction of effects in linear models with an implementation in {SPSS}},
  journal   = {Behavior Research Methods},
  year      = {2018},
  month     = {apr},
  doi       = {10.3758/s13428-018-1031-x},
  file      = {:Articles/10.3758-s13428-018-1031-x[2213].pdf:PDF},
  publisher = {Springer Nature},
}

@Comment{jabref-meta: databaseType:bibtex;}
