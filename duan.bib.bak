% Encoding: UTF-8
@article{doi:10.1175/1520-0434(2004)019<0391:TBWCWR>2.0.CO;2,
author = { M. S.  Roulston  and  L. A.  Smith },
title = {The Boy Who Cried Wolf Revisited: The Impact of False Alarm Intolerance on Cost–Loss Scenarios},
journal = {Weather and Forecasting},
volume = {19},
number = {2},
pages = {391-397},
year = {2004},
doi = {10.1175/1520-0434(2004)019<0391:TBWCWR>2.0.CO;2},

URL = { 
        https://doi.org/10.1175/1520-0434(2004)019<0391:TBWCWR>2.0.CO;2
    
},
eprint = { 
        https://doi.org/10.1175/1520-0434(2004)019<0391:TBWCWR>2.0.CO;2
    
}
,
    abstract = { Abstract Meteorologists often interpret the value of a probabilistic weather forecast using the binary cost–loss scenario. The socioeconomic benefit of such a forecast will depend on the compliance rate of users and, hence, the number of warnings that are not followed by the corresponding high-impact weather. A modified version of the canonical binary cost–loss problem in which the compliance rate of users is a function of the warning probability threshold, and hence of the “false alarm rate”, is presented. In this version of the problem, the value of the forecast can be enhanced by choosing a probability warning threshold that is higher than the cost–loss ratio. It is found that the advantage of modifying the probability warning threshold is greatest when the frequency of highly confident forecasts of an event is relatively high and when users are moderately intolerant of false alarms. Using this simple example it is illustrated that forecasters who issue nonprobabilistic, or “unequivocal,” forecasts are making implicit assumptions about the false alarm intolerance of users, as well as assumptions about their cost– loss ratios. Adopting a probabilistic approach to forecasting avoids these assumptions and separates the activity of forecasting from the activity of decision making. }
}

@InProceedings{10.1007/978-981-10-5699-4_50,
  author    = {Gupta, Surbhi and Singhal, Abhishek},
  title     = {Dynamic Classification Mining Techniques for Predicting Phishing URL},
  booktitle = {Soft Computing: Theories and Applications},
  year      = {2018},
  editor    = {Pant, Millie and Ray, Kanad and Sharma, Tarun K. and Rawat, Sanyog and Bandyopadhyay, Anirban},
  pages     = {537--546},
  address   = {Singapore},
  publisher = {Springer Singapore},
  abstract  = {The online community faces the security challenge due to Phishing attack because many numbers of transactions are performed online to save time of users. It is a continual threat, and the risk of this attack is mostly on social networking sites such as Facebook, Twitter, LinkedIn, and Google+. In this paper, a dynamic approach based on minimum time to detect Phishing URL by using classification technique is described. This approach is based on different parameters such as high accuracy, Recall, Precision, Specification, and many more. The analysis result of these algorithms shows that Random tree is a good classification technique with comparison to others; it takes very less training build data time.},
  isbn      = {978-981-10-5699-4},
}

@InProceedings{10.1007/978-981-10-3932-4_3,
  author    = {Gautam, Sudhanshu and Rani, Kritika and Joshi, Bansidhar},
  title     = {Detecting Phishing Websites Using Rule-Based Classification Algorithm: A Comparison},
  booktitle = {Information and Communication Technology for Sustainable Development},
  year      = {2018},
  editor    = {Mishra, Durgesh Kumar and Nayak, Malaya Kumar and Joshi, Amit},
  pages     = {21--33},
  address   = {Singapore},
  publisher = {Springer Singapore},
  abstract  = {In today's time, phishy website detection is one of the important challenges in the field of information security due to the large numbers of online transactions going through over the websites. Website phishing means stealing one's personal information over the Internet such as system backup data, user login credentials, bank account details or other security information. Phishing means creation of phishy or fake websites which look like legitimate ones. In this research paper, we use the associative classification data mining approach that is also named as rule-based classification technique by which we can detect a phishy website and thereby identifying the better detection algorithm which has a higher accuracy detection rate. The algorithms used are Na{\"i}ve Bayes and PART algorithms of associative classification data mining approach. Moreover, we classify the websites into a legitimate website or a phishy website from the collected datasets of websites. The implementation will be done on the datasets of 1,353 websites which contain phishy sites as well as legitimate sites. At the end, results will show us the higher accuracy detection rate algorithm, which will more correctly identify phishing or legitimate websites.},
  isbn      = {978-981-10-3932-4},
}

@InProceedings{8004877,
  author    = {N. Abdelhamid and F. Thabtah and H. Abdel-jaber},
  title     = {Phishing detection: A recent intelligent machine learning comparison based on models content and features},
  booktitle = {2017 IEEE International Conference on Intelligence and Security Informatics (ISI)},
  year      = {2017},
  pages     = {72-77},
  month     = {July},
  doi       = {10.1109/ISI.2017.8004877},
  file      = {:C\:/Users/cjdua/Documents/A-dynamic-self-structuring-neural-network-model-to-combat-phishing.pdf:PDF},
  keywords  = {Internet;Web sites;computer crime;learning (artificial intelligence);trusted computing;ML predictive models;World Wide Web;anti-phishing tools;data analysis;fake Websites;financial assets;intelligent machine learning comparison;online attack;online community;phishing attacks;phishing datasets;phishing detection rate;trusted Websites;Artificial neural networks;Classification algorithms;Decision trees;Predictive models;Security;Tools;Training;Computer Security;Machine Learning;Phishing Detection;Web Threat},
}

@Article{Ley-Borras2015,
  author    = {Roberto Ley-Borr{\'{a}}s},
  title     = {Deciding on the Decision Situation to Analyze: The Critical First Step of a Decision Analysis},
  journal   = {Decision Analysis},
  year      = {2015},
  volume    = {12},
  number    = {1},
  pages     = {46--58},
  month     = {mar},
  abstract  = {Using the right decision frame, in the sense of selecting the right decision situation to analyze, is regarded as a critical part of a decision analysis effort, but there are few guidelines on how to systematically generate alternative decision situations and how to select the best one. In practice, the decision situation is typically not explicitly selected, or even well defined, which easily leads to deciding about treating symptoms instead of underlying causes; to deciding with a narrow scope that misses important elements; and, in general, to missing the opportunity of analyzing valuable alternative decision situations.
This paper presents several distinctions and three approaches for generating significantly different decision situations and selecting the one that is best for the decision maker’s current priorities and circumstances. A key element of this work is treating the selection of the decision situation as a decision in its own right and using decision analysis tools to generate a rich set of alternative decision situations and gain clarity on which element of the set is most valuable to analyze.},
  doi       = {10.1287/deca.2014.0308},
  keywords  = {decision frame; framing; decision analysis process; decision situation; focus; extent },
  publisher = {Institute for Operations Research and the Management Sciences ({INFORMS})},
}

@Article{Nohdurft2017,
  author    = {Eike Nohdurft and Elisa Long and Stefan Spinler},
  title     = {Was Angelina Jolie Right? Optimizing Cancer Prevention Strategies Among {BRCA} Mutation Carriers},
  journal   = {Decision Analysis},
  year      = {2017},
  volume    = {14},
  number    = {3},
  pages     = {139--169},
  month     = {sep},
  abstract  = {Female carriers of a BRCA1 or BRCA2 genetic mutation face significantly elevated risks of cancer, with 45%–65% of women developing breast cancer and 15%–39% developing ovarian cancer in their lifetimes. Prophylactic surgery options to reduce cancer risk include a bilateral mastectomy (BM), bilateral salpingo-oophorectomy (BSO), or both surgeries. No comprehensive model providing recommendations at which age to perform the surgeries to optimize quality-adjusted life years (QALYs) exists. Using available clinical data, we develop a Markov decision process model of a mutation carrier’s health states and corresponding transitions, including age-dependent breast and ovarian cancer risk, distribution of each cancer subtype and stage, and mortality. We convert the problem to a linear program to solve for the optimal surgery sequence that maximizes the carrier’s expected lifetime QALYs under varying assumptions about individual patient preferences on postsurgery quality of life, fertility considerations, advances in cancer screening or treatment, and others. Baseline results demonstrate that a QALY-maximizing sequence recommends BM between ages 30 and 60 and BSO after age 40. Surgeries are recommended later for BRCA2 mutation carriers, given their lower risk for both cancers compared to BRCA1 mutation carriers. We derive structural properties from the model and show that when a carrier has already undergone one surgery, there exists an optimal control limit beyond which performing the other surgery is always QALY maximizing.

Keywords: healthcare; Markov decision process; decision analytic model; linear programming; breast cancer; ovarian cancer; BRCA mutation },
  doi       = {10.1287/deca.2017.0352},
  file      = {:Articles/deca.2017.0352[1713].pdf:PDF},
  publisher = {Institute for Operations Research and the Management Sciences ({INFORMS})},
}

@Article{Howard2005,
  author    = {Ronald A. Howard and James E. Matheson},
  title     = {Influence Diagrams},
  journal   = {Decision Analysis},
  year      = {2005},
  volume    = {2},
  number    = {3},
  pages     = {127--143},
  month     = {sep},
  abstract  = {Keywords: influence diagram ; expansion ; expansion order ; decision tree ; decision-tree order ; Bayes ; arrow reversal ; decision network ; decision-tree network ; value of clairvoyance ; Bayesian network ; belief network ; knowledge map },
  doi       = {10.1287/deca.1050.0020},
  publisher = {Institute for Operations Research and the Management Sciences ({INFORMS})},
}

@Article{Keeney2004,
  author    = {Ralph L. Keeney},
  title     = {Making Better Decision Makers},
  journal   = {Decision Analysis},
  year      = {2004},
  volume    = {1},
  number    = {4},
  pages     = {193--204},
  month     = {dec},
  abstract  = {Decision analysis has been used to help solve numerous complex decisions over the last few decades. However, its power as a basis for structuring one's thinking to resolve decisions has barely been tapped. To realize this potential, we in the decision analysis community must train people to think about their decisions using the concepts and principles of decision analysis. In this process, more emphasis must be placed on structuring decisions worth thinking about, and less emphasis must be placed on analyzing structured decisions. This paper outlines what we should do to train people to be better decision makers and why this is important. It includes a description of what we must learn to do this effectively.
Keywords: training decision makers ; role of decision analysis ; decisions worth thinking about ; structuring decisions ; analyzing decisions },
  doi       = {10.1287/deca.1040.0009},
  publisher = {Institute for Operations Research and the Management Sciences ({INFORMS})},
}

@Misc{Mohammad2015,
  author    = {Mohammad, Rami M},
  title     = {Phishing Websites Features},
  year      = {2015},
  abstract  = {If an IP address is used as an alternative of the domain name in the URL, such as 
“http://125.98. 3.123/fake. html”, users can be sure that someone is trying to steal their 
personal information. Sometimes, the IP address is even transformed into hexadecimal code 
as shown in the following link “http://0x58. 0xCC. 0xCA. 0x62/2/paypal. ca/index. html”.},
  doi       = {10.13140/rg.2.1.2595.6000},
  file      = {:C\:/Users/cjdua/Documents/PhishingWebsitesFeatures.pdf:PDF},
  language  = {en},
  pages     = {-},
  publisher = {Unpublished},
}

@InProceedings{7727750,
  author    = {F. Thabtah and R. M. Mohammad and L. McCluskey},
  title     = {A dynamic self-structuring neural network model to combat phishing},
  booktitle = {2016 International Joint Conference on Neural Networks (IJCNN)},
  year      = {2016},
  pages     = {4221-4226},
  month     = {July},
  abstract  = {Creating a neural network based classification model is commonly accomplished using the trial and error technique. However, this technique has several difficulties in terms of time wasted and the availability of experts. In this article, an algorithm that simplifies structuring neural network classification models is proposed. The algorithm aims at creating a large enough structure to learn models from the training dataset that can be generalised on the testing dataset. Our algorithm dynamically tunes the structure parameters during the training phase aiming to derive accurate non-overfitting classifiers. The proposed algorithm has been applied to phishing website classification problem and it shows competitive results with respect to various evaluation measures such as harmonic mean (F1-score), precision, and classification accuracy.},
  doi       = {10.1109/IJCNN.2016.7727750},
  file      = {:C\:/Users/cjdua/Documents/A-dynamic-self-structuring-neural-network-model-to-combat-phishing.pdf:PDF},
  keywords  = {Internet;computer crime;neural nets;pattern classification;combat phishing;dataset testing;dataset training;neural network based classification model;phishing Website classification problem;Artificial neural networks;Biological neural networks;Classification algorithms;Density estimation robust algorithm;Heuristic algorithms;Neurons;Training;Classification;Constructive pruning;Neural Network;Phishing},
}

@InProceedings{Pang+Lee+Vaithyanathan:02a,
  author    = {Bo Pang and Lillian Lee and Shivakumar Vaithyanathan},
  title     = {Thumbs Up? Sentiment Classification Using Machine Learning Techniques},
  booktitle = {Proceedings of EMNLP},
  year      = {2002},
  pages     = {79--86},
  abstract  = {We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. Using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines. However, the three machine learning methods we employed (Naive Bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization. We conclude by examining factors that make the sentiment classification problem more challenging.},
}

@Book{box1987empirical,
  title     = {Empirical model-building and response surfaces.},
  publisher = {John Wiley \& Sons},
  year      = {1987},
  author    = {Box, George EP and Draper, Norman R},
  abstract  = {Box repeated the aphorism twice more in his 1987 book, Empirical Model-Building and Response Surfaces (which was co-authored with Norman Draper).[3] The first repetition is on p. 74: "Remember that all models are wrong; the practical question is how wrong do they have to be to not be useful." The second repetition is on p. 424: "Essentially, all models are wrong, but some are useful".},
}

@Book{Agrawal2018,
  title     = {Prediction Machines: The Simple Economics of Artificial Intelligence},
  publisher = {Harvard Business Review Press},
  year      = {2018},
  author    = {Ajay Agrawal and Joshua Gans and Avi Goldfarb},
  month     = apr,
  isbn      = {978-1633695672},
  abstract  = {"What does AI mean for your business? Read this book to find out." -- Hal Varian, Chief Economist, Google

Artificial intelligence does the seemingly impossible, magically bringing machines to life--driving cars, trading stocks, and teaching children. But facing the sea change that AI will bring can be paralyzing. How should companies set strategies, governments design policies, and people plan their lives for a world so different from what we know? In the face of such uncertainty, many analysts either cower in fear or predict an impossibly sunny future.

But in Prediction Machines, three eminent economists recast the rise of AI as a drop in the cost of prediction. With this single, masterful stroke, they lift the curtain on the AI-is-magic hype and show how basic tools from economics provide clarity about the AI revolution and a basis for action by CEOs, managers, policy makers, investors, and entrepreneurs.

When AI is framed as cheap prediction, its extraordinary potential becomes clear:

Prediction is at the heart of making decisions under uncertainty. Our businesses and personal lives are riddled with such decisions.
Prediction tools increase productivity--operating machines, handling documents, communicating with customers.
Uncertainty constrains strategy. Better prediction creates opportunities for new business structures and strategies to compete.
Penetrating, fun, and always insightful and practical, Prediction Machines follows its inescapable logic to explain how to navigate the },
  review    = {Lawrence H. Summers, Charles W. Eliot Professor, former president, Harvard University; former secretary, US Treasury; and former chief economist, World Bank--
"AI may transform your life. And Prediction Machines will transform your understanding of AI. This is the best book yet on what may be the best technology that has come along."

Susan Athey, Economics of Technology Professor, Stanford University; former consulting researcher, Microsoft Research New England--
"Prediction Machines is a path-breaking book that focuses on what strategists and managers really need to know about the AI revolution. Taking a grounded, realistic perspective on the technology, the book uses principles of economics and strategy to understand how firms, industries, and management will be transformed by AI."

Dominic Barton, Global Managing Partner, McKinsey & Company--
"Prediction Machines achieves a feat as welcome as it is unique: a crisp, readable survey of where artificial intelligence is taking us separates hype from reality, while delivering a steady stream of fresh insights. It speaks in a language that top executives and policy makers will understand. Every leader needs to read this book."

Kevin Kelly, founding executive editor, Wired; author, What Technology Wants and The Inevitable--
"This book makes artificial intelligence easier to understand by recasting it as a new, cheap commodity--predictions. It's a brilliant move. I found the book incredibly useful."},
}

@Article{Agrawal2017,
  author    = {Ajay Agrawal and Joshua Gans and Avi Goldfarb},
  title     = {How AI Will Change the Way We Make Decisions},
  year      = {2017},
  month     = jul,
  abstract  = {Recent advances in AI are best thought of as a drop in the cost of prediction. Prediction is useful because it helps improve decisions. But it isn’t the only input into decision-making; the other key input is judgment. Judgment is the process of determining what the reward to a particular action is in a particular environment. In many cases, especially in the near term, humans will be required to exercise this sort of judgment. They’ll specialize in weighing the costs and benefits of different decisions, and then that judgment will be combined with machine-generated predictions to make decisions. But couldn’t AI calculate costs and benefits itself? Yes, but someone would have had to program the AI as to what the appropriate profit measure is. This highlights a particular form of human judgment that we believe will become both more common and more valuable.},
  timestamp = {2018-02-13},
  url       = {https://hbr.org/2017/07/how-ai-will-change-the-way-we-make-decisions},
}

@Article{ABCNews,
  author    = {MATT O'BRIEN AND DAKE KANG},
  title     = {AI in the court: When algorithms rule on jail time},
  journal   = {NewsABC},
  year      = {2018},
  abstract  = {The centuries-old process of releasing defendants on bail, long the province of judicial discretion, is getting a major assist ... courtesy of artificial intelligence.

In late August, Hercules Shepherd Jr. walked up to the stand in a Cleveland courtroom, dressed in an orange jumpsuit. Two nights earlier, an officer had arrested him at a traffic stop with a small bag of cocaine, and he was about to be arraigned.

Judge Jimmy Jackson Jr. looked at Shepherd, then down at a computer-generated score on the front of the 18-year-old's case file. Two out of six for likelihood of committing another crime. One out of six for likelihood of skipping court. The scores marked Shepherd as a prime candidate for pretrial release with low bail.

"We ask the court to take that all into consideration," said Shepherd's public defender, David Magee.},
  timestamp = {2018-02-14},
  url       = {https://abcnews.go.com/Technology/wireStory/ai-court-algorithms-rule-jail-time-52732343},
}

@Article{Gillion2018,
  author    = {Kirstin Gillon},
  title     = {Training AI to be unbiased must be a priority, not an afterthought},
  year      = {2018},
  timestamp = {2018-02-13},
  url       = {http://www.cityam.com/280311/training-ai-unbiased-must-priority-not-afterthought},
}

@Article{Kleinberg2017,
  author    = {Jon Kleinberg and Himabindu Lakkaraju and Jure Leskovec and Jens Ludwig and Sendhil Mullainathan},
  title     = {Human Decisions and Machine Predictions},
  journal   = {The Quarterly Journal of Economics},
  year      = {2017},
  month     = {aug},
  abstract  = {Can machine learning improve human decision making? Bail decisions provide a good test case. Millions of times each year, judges make jail-or-release decisions that hinge on a prediction of what a defendant would do if released. The concreteness of the prediction task combined with the volume of data available makes this a promising machine-learning application. Yet comparing the algorithm to judges proves complicated. First, the available data are generated by prior judge decisions. We only observe crime outcomes for released defendants, not for those judges detained. This makes it hard to evaluate counterfactual decision rules based on algorithmic predictions. Second, judges may have a broader set of preferences than the variable the algorithm predicts; for instance, judges may care specifically about violent crimes or about racial inequities. We deal with these problems using different econometric strategies, such as quasi-random assignment of cases to judges. Even accounting for these concerns, our results suggest potentially large welfare gains: one policy simulation shows crime reductions up to 24.7% with no change in jailing rates, or jailing rate reductions up to 41.9% with no increase in crime rates. Moreover, all categories of crime, including violent crimes, show reductions; these gains can be achieved while simultaneously reducing racial disparities. These results suggest that while machine learning can be valuable, realizing this value requires integrating these tools into an economic framework: being clear about the link between predictions and decisions; specifying the scope of payoff functions; and constructing unbiased decision counterfactuals. JEL Codes: C10, C55, K40.},
  doi       = {10.1093/qje/qjx032},
  file      = {:C\:/Users/cjdua/Documents/qjx032.pdf:PDF},
  publisher = {Oxford University Press ({OUP})},
}

@Article{Kleinberg2018,
  author   = {Kleinberg, Jon and Mullainathan, Sendhil and Shah, Anuj K and Yeomans, Mike},
  title    = {Making Sense of Recommendations},
  journal  = {Management Science},
  year     = {2018},
  abstract = {Computer algorithms are increasingly being used to predict people’s preferences and make
recommendations. These recommender systems, however, differ from prior prediction algorithms. Prior
algorithms still relied on human input and expertise. Those algorithms simply improved human
judgment by making it more consistent. But modern recommendation algorithms are not built on
human models of judgment. These are the primary algorithms people encounter today, but we do not
know how they compare to human judgment. Here, we compare computer recommender systems to
human recommenders in a highly subjective domain: predicting which jokes people will find funny. We
find that recommender systems outperform humans, whether strangers, friends, or family. Yet people
are averse to relying on these recommender systems. This aversion partly stems from the fact that
people believe the human recommendation process is easier to understand. It is not enough for
recommender systems to be accurate, they must also be understood.
Keywords: Recommendations; Decision-Making; Machine Learning; Algorithms},
  file     = {:C\:/Users/cjdua/Documents/Making_Sense.pdf:PDF},
}

@Article{Rosso2015,
  author   = {Cami Rosso},
  title    = {The Conundrum of Machine Learning and Cognitive Biases},
  journal  = {Medium},
  year     = {2015},
  abstract = {Machine learning is on the rise due to the technological convergence of the growth of big data, decreasing data storage costs, increasing computing power, improved artificial intelligence algorithms and acceleration of cloud computing. Machine learning is the ability for computers to learn without explicit programming. It’s analogous to the human ability to identify an octopus based on the set of data input that goes to the brain, such as eight arms, tentacles, lack of skeleton and other characteristics, without having prior knowledge of every type of cephalopod mollusk in existence.

However, human decision-making is subject to numerous cognitive biases that can easily distort judgement. For example, iconoclastic author Tom Peters highlights 159 cognitive biases that impact management decision-making [1]. Emotions such as anxiety, fear or anger could easily cloud a person’s judgement. Human thinking is prone to the use of cognitive heuristics, a shortcut that may lead to biases and faulty decisions.

Given a computer is devoid of emotion and the hubris of human ego, it would seem logical that machine learning is not impacted by cognitive bias. The caveat is that humans are creating and monitoring the programming for machine learning. The areas of cognitive bias vulnerability for machine learning include:

Data structure, collection and sources
Data set size
Level of objectivity in the data
Weight assignments to data points
The absence or inclusion of indicators
The inherent cognitive biases of the human programmer
Machine learning technology is deployed today for many business uses, including self-driving cars, online recommendation, search engines, handwriting recognition, computer vision, online ad serving, pricing, prediction of equipment failure, credit scoring, fraud detection, OCR (optical character recognition), spam filtering and many other uses. The growing ubiquity of machine learning in business makes it critical to mitigate the introduction of human cognitive biases into the machine.

References

Peters, Tom. “159 Cognitive Biases Between You and Good Judgment Good Luck!” May 29, 2014.},
}

@Article{Rosso2018,
  author   = {Cami Rosso},
  title    = {The Human Bias in the AI Machine},
  journal  = {Psychology Today},
  year     = {2018},
  month    = feb,
  abstract = {Artificial intelligence (AI) can result in positive advancements and unintended negative consequences. A key area that warrants further research is the impact of human cognitive bias on AI. Harvard and MIT Professor George Church, Singularity University Neil Jacobstein, MIT Physicist Max Tegmark, Behavioral Economics and Data Scientist Colin W.P. Lewis, Ph.D., Oxford Professor of Philosophy Nick Bostrom, SpaceX and Tesla Motors Founder Elon Musk, Apple Co-founder Steve Wozniak, and Cambridge Physicist Stephen Hawking are among the over 8,000 people who have signed an open letter on artificial intelligence that seeks research on how to reap the benefits of AI while avoiding the pitfalls [1].

"Success in creating effective AI, could be the biggest event in the history of our civilization. Or the worst." Stephen Hawking, Physicist

Like the human brain, artificial intelligence is subject to cognitive bias. Human cognitive biases are heuristics, mental shortcuts that skew decision-making and reasoning, resulting in reasoning errors. Examples of cognitive biases include stereotyping, the bandwagon effect, confirmation bias, priming, selective perception, the gambler’s fallacy, and the observational selection bias. The total number of cognitive biases is constantly evolving, due to the ongoing identification of new biases.

Human cognitive bias influences AI through data, algorithms and interaction. Machine learning, a subset of AI, is the ability for computers to learn without explicit programming. AI’s learning is shaped by data, algorithms, and experience through interactions and iterations. The size, structure, collection methodology, and sources of data impact machine learning. Machine learning is dependent on the quality of learning data sets. Just like in humans, in AI the more objective the data and the larger the data set, the less possibility of distortion [2].

The common underlying factor in cognitive biases is inclination. Proneness in AI is influenced through the assignment of weight on the parameters and nodes of a neural network, a computer system modeled on the human brain. The weight may inadvertently bias the machine learning algorithm from inception via data input, through supervised training, and by intervention through manual adjustments. The absence or inclusion of indicators, and the inherent cognitive biases of the human computer programmer can cause machine learning bias [3].

The artificial intelligence revolution (AIR) is well underway [4]. Artificial intelligence is currently a tool used to assist humans and is being deployed as point solutions across a wide variety of functions such as personal digital assistants, email filtering, search, fraud prevention, engineering, marketing models, digital distribution, voice recognition, facial recognition, content classification, natural language, video production, news generation, play and game-play analytics, customer service, financial reporting, marketing optimization, energy cost management, pricing, inventory, enterprise applications, and more functions [5]. Some of the greatest thinkers of the 21st century have warned of the dangers of AI unchecked. The increasing pervasiveness of AI necessitates the minimization of human cognitive bias in the machine. The future of humanity may very well depend on it.},
  url      = {https://www.psychologytoday.com/blog/the-future-brain/201802/the-human-bias-in-the-ai-machine},
}

@Article{Gal2018,
  author  = {Uri Gal},
  title   = {Predictive algorithms are no better at telling the future than a crystal ball},
  journal = {The Conversation},
  year    = {2018},
  month   = feb,
  review  = {An increasing number of businesses invest in advanced technologies that can help them forecast the future of their workforce and gain a competitive advantage.

Many analysts and professional practitioners believe that, with enough data, algorithms embedded in People Analytics (PA) applications can predict all aspects of employee behavior: from productivity, to engagement, to interactions and emotional states.

Read more:  Digital public: looking at what algorithms actually do

Predictive analytics powered by algorithms are designed to help managers make decisions that favourably impact the bottom line. The global market for this technology is expected to grow from US$3.9 billion in 2016 to US$14.9 billion by 2023.

Despite the promise, predictive algorithms are as mythical as the crystal ball of ancient times.

Predictive models are based on flawed reasoning
One of the fundamental flaws of predictive algorithms is their reliance on “inductive reasoning”. This is when we draw conclusions based on our knowledge of a small sample, and assume that those conclusions apply across the board.

For example, a manager might observe that all of her employees with an MBA are highly motivated. She therefore concludes that all workers with an MBA are highly motivated.

This conclusion is flawed because it assumes that past patterns will remain consistent. This assumption itself can only be true because of our experience to date, which confirms this consistency. In other words, inductive reasoning can only be inductively justified: it works because it has worked before. Therefore, there is no logical reason to assume that the next person our company hires who has an MBA degree will be highly motivated.

Read more:  How marketers use algorithms to (try to) read your mind

Assumptions like these can be coded into hiring algorithms, which, in this case, would assign a weighting to all job applicants with an MBA degree. But when inductive reasoning is baked into the code of hiring applications, it can lead to unfounded decisions, adversely impact on the bottom-line, and even discriminate against certain groups of people.

For example, a tool used in some parts of the United States to assess whether a person arrested for a crime would re-offend was found to unfairly discriminate against African Americans.

They lead to self-fulfilling prophecies
Another flaw in the predictions thrown up by algorithmic analysis is their propensity to create self-fulfilling prophecies. Acting on algorithmic predictions, managers can create the conditions that ultimately realise those very predictions.

For example, a company may use an algorithm to predict the performance of its recently-hired salespeople. Such an algorithm might draw on data from standardised tests completed during their onboarding process, reviews from previous employers, and demographics. This analysis can then be used to rank new salespeople and justify the allocation of more training resources to those believed to have greater performance potential.

This is likely to produce the very results that the initial analysis predicted. The higher-ranked recruits will perform better than those ranked lower on the list because they have been given superior training opportunities.

Read more:  What businesses can learn from sports about using algorithms

Calculating probabilities of future events is meaningless
Some practitioners recognise the flaws in the predictive capability of algorithmic systems, but they still see value in generating models that indicate probability.

Rather than predicting the occurrence of future events or states, probabilistic models can indicate the degree of certainty that events or situations might occur in the future.

However, here too it pays to be a little sceptical. When a model calculates that an event is likely to happen it does so as a percentage of 100% certainty. Any probabilistic prediction is only possible in relation to the possibility of complete certainty. But since complete certainty is impossible to predict, probabilistic models are of no real significance either.

Algorithms don’t ‘predict’, they ‘extrapolate’
So if they cannot predict organisational events with complete or even probable certainty, what can predictive algorithms do?

To answer this, we must understand how they work. Once developed and inscribed with their base code, predictive algorithms need to be “trained” to hone their predictive power. This is done by feeding them with past organisational data. They then search for trends in the data and extrapolate rules that can be applied to future data.

For example, workforce planning algorithms can identify employees who are likely to resign. They do this by analysing the personality and behavioural patterns of employees who have resigned in the past and cross-referencing the results with the profiles of existing employees to identify those with the highest matching scores. With each round of application, the algorithm is continually adjusted to correct ever-decreasing prediction errors.

Read more:  Why marking essays by algorithm risks rewarding the writing of 'bullshit'

However, the term “prediction error” is misleading because these algorithms do not predict, but rather extrapolate. All that predictive algorithms can ever do is guess at what is going to happen based on what has already happened. The leap required to make actual predictions is not a matter of computing power, but rather of bending the laws of physics.

Predictive models can’t anticipate change
Because they are extrapolative, predictive models are rather good at identifying regularities, continuity and routine. However, the human brain is also designed to identify stable patterns. Competent managers should be well aware of their organisation’s operations, and capable of envisioning steady patterns over time.

What managers find difficult to predict is change. Unfortunately, predictive models are also poor predictors of change. The more radical change is – different from existing patterns – the more poorly predicted it will be.

To manage effectively and develop their knowledge of current and likely organisational events, managers need to learn to build and trust their instinctual awareness of emerging processes rather than rely on algorithmic promises that cannot be realised. The key to effective decision-making is not algorithmic calculations but intuition.},
  url     = {https://theconversation.com/predictive-algorithms-are-no-better-at-telling-the-future-than-a-crystal-ball-91329},
}

@Article{Caliskan2017,
  author    = {Aylin Caliskan and Joanna J. Bryson and Arvind Narayanan},
  title     = {Semantics derived automatically from language corpora contain human-like biases},
  journal   = {Science},
  year      = {2017},
  volume    = {356},
  number    = {6334},
  pages     = {183--186},
  month     = {apr},
  abstract  = {Machine learning is a means to derive artificial intelligence by discovering patterns in existing data. Here we show that applying machine learning to ordinary human language results in human-like semantic biases. We replicate a spectrum of known biases, as measured by the Implicit Association Test, using a widely used, purely statistical machine-learning model trained on a standard corpus of text from the Web. Our results indicate that text corpora contain recoverable and accurate imprints of our historic biases, whether morally neutral as towards insects or flowers, problematic as towards race or gender, or even simply veridical, reflecting the status quo distribution of gender with respect to careers or first names. Our methods hold promise for identifying and addressing sources of bias in culture, including technology.},
  doi       = {10.1126/science.aal4230},
  file      = {:C\:/Users/cjdua/Documents/155388415.pdf:PDF},
  publisher = {American Association for the Advancement of Science ({AAAS})},
}

@Article{Moscati2016,
  author = {Ivan Moscati},
  title  = {Retrospectives: How Economists Came to Accept Expected Utility Theory: The Case of Samuelson and Savage},
  year   = {2016},
  volume = {30},
  pages  = {219-236},
  issn   = {0895-3309},
  doi    = {10.1257/jep.30.2.219},
  file   = {:Articles/Moscati_Samuelson_and_Savage_on_EUT_JEP_201620160303182942.pdf:PDF},
}

@Article{Zhang2002,
  author = {Jiankang Zhang},
  title  = {Subjective ambiguity, expected utility and Choquet expected utility},
  year   = {2002},
  volume = {20},
  pages  = {159-181},
  issn   = {0938-2259},
  doi    = {10.1007/s001990100207},
}

@Article{Samuelson1988,
  author = {Paul A. Samuelson},
  title  = {How a certain internal consistency entails the expected utility dogma},
  year   = {1988},
  volume = {1},
  pages  = {389-393},
  issn   = {0895-5646},
  doi    = {10.1007/bf00117642},
}

@Misc{HAGEN1991,
  author = {Ole HAGEN},
  title  = {Expected Utility Theory - The “Confirmation” That Backfires},
  year   = {1991},
  doi    = {10.1007/978-94-011-3146-9_7},
  pages  = {105-114},
}

@Article{Casadesus-Masanell2000,
  author = {Ramon Casadesus-Masanell and Peter Klibanoff and Emre Ozdenoren},
  title  = {Maxmin Expected Utility over Savage Acts with a Set of Priors},
  year   = {2000},
  volume = {92},
  pages  = {35-65},
  issn   = {0022-0531},
  doi    = {10.1006/jeth.1999.2630},
}

@Article{Blavatskyy,
  author   = {Pavlo R. Blavatskyy},
  title    = {A Theory of Decision-Making Under Risk as a Tradeoff between Expected Utility, Expected Utility Deviation and Expected Utility Skewness},
  journal  = {SSRN},
  year     = {2014},
  issn     = {1556-5068},
  abstract = {This paper presents a new decision theory for modelling choice under risk. The new theory is a two-parameter generalization of expected utility theory. The proposed theory assumes that a decision maker: 1) behaves as if maximizing expected utility; but 2) may experience disappointment (elation) when the utility of a lottery’s outcome falls short of (exceeds) the expected utility of the lottery; and 3) may have a preference for gambling (attraction/aversion to positively/negatively skewed lotteries). The proposed theory can rationalize the fourfold pattern of risk attitudes; the common ratio effect and the reverse thereof (in certain types of decision problems); the Allais paradox in classical common consequence problems and the reverse Allais paradox — in common consequence problems with an even split of a probability mass; violations of the betweenness axiom; switching behavior in the Samuelson’s example; violations of ordinal, upper and lower cumulative independence (which falsify rank-dependent utility and cumulative prospect theory); and preference reversals between valuations and choice. Behavioral characterization (axiomatization) of the theory is provided. In application to insurance, the theory can rationalize full insurance with an actuarially unfair premium and aversion to probabilistic insurance. In application to optimal portfolio investment, the theory can rationalize the equity premium puzzle.

Keywords: Decision Theory, Risk, Expected Utility Theory, Allais paradox, Disappointment, Equity Premium Puzzle, Insurance, fourfold pattern of risk attitudes, common ratio effect, preference reversals},
  doi      = {10.2139/ssrn.2505828},
}

@Article{Jagatic2007,
  author        = {Tom N. Jagatic and Nathaniel A. Johnson and Markus Jakobsson and Filippo Menczer},
  title         = {Social phishing},
  year          = {2007},
  volume        = {50},
  pages         = {94-100},
  issn          = {0001-0782},
  __markedentry = {[cjdua:]},
  doi           = {10.1145/1290958.1290968},
}

@Book{jakobsson2006phishing,
  title     = {Phishing and countermeasures: understanding the increasing problem of electronic identity theft},
  publisher = {John Wiley \& Sons},
  year      = {2006},
  author    = {Jakobsson, Markus and Myers, Steven},
}

@Misc{mitchell1997machine,
  author    = {Mitchell, Tom M},
  title     = {Machine learning},
  year      = {1997},
  publisher = {McGraw-Hill Boston, MA:},
}

@Book{rao2013handbook,
  title     = {Handbook of Statistics, Volume 31: Machine Learning Theory and Applications},
  publisher = {North Holland \& IFIP},
  year      = {2013},
  author    = {Rao, C Radhakrishna and Govindaraju, Venu},
}

@Article{cottrell2006new,
  author  = {Cottrell, Garrison W},
  title   = {New life for neural networks},
  journal = {networks},
  year    = {2006},
  volume  = {5},
  pages   = {6},
}

@Misc{Lichman:2013,
  author      = {M. Lichman},
  title       = {{UCI} Machine Learning Repository},
  year        = {2013},
  institution = {University of California, Irvine, School of Information and Computer Sciences},
  url         = {http://archive.ics.uci.edu/ml},
}

@Article{Mohammad2015a,
  author    = {Rami M. Mohammad and Fadi Thabtah and Lee McCluskey},
  title     = {Tutorial and critical analysis of phishing websites methods},
  journal   = {Computer Science Review},
  year      = {2015},
  volume    = {17},
  pages     = {1--24},
  month     = {aug},
  abstract  = {The Internet has become an essential component of our everyday social and financial activities. Internet is not important for individual users only but also for organizations, because organizations that offer online trading can achieve a competitive edge by serving worldwide clients. Internet facilitates reaching customers all over the globe without any market place restrictions and with effective use of e-commerce. As a result, the number of customers who rely on the Internet to perform procurements is increasing dramatically. Hundreds of millions of dollars are transferred through the Internet every day. This amount of money was tempting the fraudsters to carry out their fraudulent operations. Hence, Internet users may be vulnerable to different types of web threats, which may cause financial damages, identity theft, loss of private information, brand reputation damage and loss of customers’ confidence in e-commerce and online banking. Therefore, suitability of the Internet for commercial transactions becomes doubtful. Phishing is considered a form of web threats that is defined as the art of impersonating a website of an honest enterprise aiming to obtain user’s confidential credentials such as usernames, passwords and social security numbers. In this article, the phishing phenomena will be discussed in detail. In addition, we present a survey of the state of the art research on such attack. Moreover, we aim to recognize the up-to-date developments in phishing and its precautionary measures and provide a comprehensive study and evaluation of these researches to realize the gap that is still predominating in this area. This research will mostly focus on the web based phishing detection methods rather than email based detection methods.},
  doi       = {10.1016/j.cosrev.2015.04.001},
  file      = {:Articles/Tutorial_and_Critical_Analysis_of_Phishing_Websites_Methods.pdf:PDF},
  keywords  = {PhishingAnti-phishingData miningBlacklistWhitelist},
  publisher = {Elsevier {BV}},
}

@Article{Mohammad2013,
  author    = {Rami M. Mohammad and Fadi Thabtah and Lee McCluskey},
  title     = {Predicting phishing websites based on self-structuring neural network},
  journal   = {Neural Computing and Applications},
  year      = {2013},
  volume    = {25},
  number    = {2},
  pages     = {443--458},
  month     = {nov},
  abstract  = {Internet has become an essential component of our everyday social and financial activities. Nevertheless, internet users may be vulnerable to different types of web threats, which may cause financial damages, identity theft, loss of private information, brand reputation damage and loss of customer’s confidence in e-commerce and online banking. Phishing is considered as a form of web threats that is defined as the art of impersonating a website of an honest enterprise aiming to obtain confidential information such as usernames, passwords and social security number. So far, there is no single solution that can capture every phishing attack. In this article, we proposed an intelligent model for predicting phishing attacks based on artificial neural network particularly self-structuring neural networks. Phishing is a continuous problem where features significant in determining the type of web pages are constantly changing. Thus, we need to constantly improve the network structure in order to cope with these changes. Our model solves this problem by automating the process of structuring the network and shows high acceptance for noisy data, fault tolerance and high prediction accuracy. Several experiments were conducted in our research, and the number of epochs differs in each experiment. From the results, we find that all produced structures have high generalization ability.

Keywords
Web threat Phishing Information security Neural network Data mining },
  doi       = {10.1007/s00521-013-1490-z},
  file      = {:Articles/RamiPredicting_Phishing_Websites_based_on_Self-Structuring_Neural_Network.pdf:PDF},
  publisher = {Springer Nature},
}

@InProceedings{Mohammad2012,
  author        = {R. M. Mohammad and F. Thabtah and L. McCluskey},
  title         = {An assessment of features related to phishing websites using an automated technique},
  booktitle     = {Proc. Int. Conf. for Internet Technology and Secured Transactions},
  year          = {2012},
  pages         = {492--497},
  month         = dec,
  __markedentry = {[cjdua:6]},
  abstract      = {Corporations that offer online trading can achieve a competitive edge by serving worldwide clients. Nevertheless, online trading faces many obstacles such as the unsecured money orders. Phishing is considered a form of internet crime that is defined as the art of mimicking a website of an honest enterprise aiming to acquire confidential information such as usernames, passwords and social security number. There are some characteristics that distinguish phishing websites from legitimate ones such as long URL, IP address in URL, adding prefix and suffix to domain and request URL, etc. In this paper, we explore important features that are automatically extracted from websites using a new tool instead of relying on an experienced human in the extraction process and then judge on the features importance in deciding website legitimacy. Our research aims to develop a group of features that have been shown to be sound and effective in predicting phishing websites and to extract those features according to new scientific precise rules.},
  keywords      = {Web sites, computer crime, electronic money, electronic trading, IP address, Internet crime, Internet protocol, URL prefix, URL suffix, Web site legitimacy, confidential information acquisition, money order security, online trading, password, phishing Web site, social security number, username, Accuracy, Educational institutions, Feature extraction, HTML, Protocols, Reliability, World Wide Web, Phishing, Rule, Security, Website features, features extraction},
}

@Comment{jabref-meta: databaseType:bibtex;}
