% Encoding: UTF-8

@Article{Webb2018,
  author    = {J. Angus Webb and Siobhan C. de Little and Kimberly A. Miller and Michael J. Stewardson},
  title     = {Quantifying and predicting the benefits of environmental flows: Combining large-scale monitoring data and expert knowledge within hierarchical Bayesian models},
  journal   = {Freshwater Biology},
  year      = {2018},
  month     = {feb},
  doi       = {10.1111/fwb.13069},
  file      = {:C\:/Users/cjdua/Documents/Webb_et_al-2018-Freshwater_Biology.pdf:PDF},
  publisher = {Wiley-Blackwell},
}

@TechReport{li2018integrated,
  author      = {Li, Yong and Yu, Jun and Zeng, Tao},
  title       = {Integrated Deviance Information Criterion for Latent Variable Models},
  institution = {Singapore Management University, School of Economics},
  year        = {2018},
  file        = {:Articles/DIC_LatentVariable25.pdf:PDF},
}

@Article{smith2002data,
  author    = {Smith, George Davey and Ebrahim, Shah},
  title     = {Data dredging, bias, or confounding: They can all get you into the BMJ and the Friday papers},
  journal   = {BMJ: British Medical Journal},
  year      = {2002},
  volume    = {325},
  number    = {7378},
  pages     = {1437},
  publisher = {BMJ Publishing Group},
}

@Article{tipping2004bayesian,
  author    = {Tipping, Michael E},
  title     = {Bayesian inference: An introduction to principles and practice in machine learning},
  journal   = {Lecture notes in computer science},
  year      = {2004},
  volume    = {3176},
  pages     = {41--62},
  publisher = {Springer},
}

@Article{wagenmakers2007practical,
  author    = {Wagenmakers, Eric-Jan},
  title     = {A practical solution to the pervasive problems ofp values},
  journal   = {Psychonomic bulletin \& review},
  year      = {2007},
  volume    = {14},
  number    = {5},
  pages     = {779--804},
  publisher = {Springer},
}

@Book{lynch2007introduction,
  title     = {Introduction to applied Bayesian statistics and estimation for social scientists},
  publisher = {Springer Science \& Business Media},
  year      = {2007},
  author    = {Lynch, Scott M},
}

@Article{scutari2009learning,
  author  = {Scutari, Marco},
  title   = {Learning Bayesian networks with the bnlearn R package},
  journal = {arXiv preprint arXiv:0908.3817},
  year    = {2009},
}

@Article{Friedman2010Regularization,
  author  = {Jerome Friedman and Trevor Hastie and Robert Tibshirani},
  title   = {Regularization Paths for Generalized Linear Models via Coordinate Descent},
  journal = {Journal of Statistical Software},
  year    = {2010},
  volume  = {33},
  number  = {1},
  pages   = {1--22},
  url     = {http://www.jstatsoft.org/v33/i01/},
}

@InBook{Sebastiani2010,
  chapter   = {10},
  pages     = {175--208},
  title     = {Bayesian Networks},
  publisher = {Springer US},
  year      = {2010},
  author    = {Sebastiani, Paola and Abad, Maria M. and Ramoni, Marco F.},
  editor    = {Maimon, Oded and Rokach, Lior},
  address   = {Boston, MA},
  isbn      = {978-0-387-09823-4},
  abstract  = {Bayesian networks are today one of the most promising approaches to Data Mining and knowledge discovery in databases. This chapter reviews the fundamental aspects of Bayesian networks and some of their technical aspects, with a particular emphasis on the methods to induce Bayesian networks from different types of data. Basic notions are illustrated through the detailed descriptions of two Bayesian network applications: one to survey data and one to marketing data.},
  booktitle = {Data Mining and Knowledge Discovery Handbook},
  doi       = {10.1007/978-0-387-09823-4_10},
  file      = {:D\:/Dropbox/Articles/[9] 2010 Data Mining and Knowledge Discovery Handbook.pdf:PDF},
  url       = {https://doi.org/10.1007/978-0-387-09823-4_10},
}

@Article{Simon2011Coxnet,
  author  = {Noah Simon and Jerome Friedman and Trevor Hastie and Rob Tibshirani},
  title   = {Regularization Paths for Cox's Proportional Hazards Model via Coordinate Descent},
  journal = {Journal of Statistical Software},
  year    = {2011},
  volume  = {39},
  number  = {5},
  pages   = {1--13},
  url     = {http://www.jstatsoft.org/v39/i05/},
}

@Article{dienes2011bayesian,
  author    = {Dienes, Zoltan},
  title     = {Bayesian versus orthodox statistics: Which side are you on?},
  journal   = {Perspectives on Psychological Science},
  year      = {2011},
  volume    = {6},
  number    = {3},
  pages     = {274--290},
  publisher = {Sage Publications Sage CA: Los Angeles, CA},
}

@Misc{etz2016using,
  author    = {Etz, Alexander},
  title     = {Using Bayes Factors to Get the Most Out of Linear Regression: a Practical Guide Using R},
  year      = {2016},
  publisher = {Citeseer},
}

@Article{benjamin2017redefine,
  author  = {Benjamin, Daniel J and Berger, James O and Johannesson, Magnus and Nosek, Brian A and Wagenmakers, Eric-Jan and Berk, Richard and Bollen, Kenneth A and Brembs, Bj{\"o}rn and Brown, Lawrence and Camerer, Colin and others},
  title   = {Redefine statistical significance},
  journal = {Nature Human Behaviour},
  year    = {2017},
}

@Article{lobo2011short,
  author    = {Lobo, Miguel Sousa},
  title     = {A Short JAGS Tutorial with an Interpersonal Perception/Social Network Example},
  year      = {2011},
  file      = {:C\:/Users/cjdua/Documents/JAGS_tutorial_Lobo.pdf:PDF},
  publisher = {Citeseer},
}

@InProceedings{zhang2018fairness,
  author    = {Zhang, Junzhe and Bareinboim, Elias},
  title     = {Fairness in Decision-Making--The Causal Explanation Formula},
  booktitle = {Proceedings of the 32nd AAAI Conference on Artificial Intelligence},
  year      = {2018},
  doi       = {10.1155/2018/5176920},
  file      = {:C\:/Users/cjdua/Documents/r30.pdf:PDF},
}

@Article{gelman2017stents,
  author = {Gelman, Andrew and Nallamothu, Brahmajee},
  title  = {Stents: An exploration of design, measurement, analysis, and reporting in clinical research},
  year   = {2017},
  file   = {:C\:/Users/cjdua/Documents/Stent An exploration of design measurement analysis and reporting in.pdf:PDF},
}

@Article{trangucci2018voting,
  author  = {Trangucci, Rob and Ali, Imad and Gelman, Andrew and Rivers, Doug},
  title   = {Voting patterns in 2016: Exploration using multilevel regression and poststratification (MRP) on pre-election polls},
  journal = {arXiv preprint arXiv:1802.00842},
  year    = {2018},
  file    = {:C\:/Users/cjdua/Documents/1802.00842.pdf:PDF},
}

@Article{McShane2017,
  author    = {Blakeley B. McShane and David Gal},
  title     = {Statistical Significance and the Dichotomization of Evidence},
  journal   = {Journal of the American Statistical Association},
  year      = {2017},
  volume    = {112},
  number    = {519},
  pages     = {885--895},
  month     = {jul},
  abstract  = {In light of recent concerns about reproducibility and replicability, the ASA issued a Statement on Statistical Significance and p-values aimed at those who are not primarily statisticians. While the ASA Statement notes that statistical significance and p-values are “commonly misused and misinterpreted,” it does not discuss and document broader implications of these errors for the interpretation of evidence. In this article, we review research on how applied researchers who are not primarily statisticians misuse and misinterpret p-values in practice and how this can lead to errors in the interpretation of evidence. We also present new data showing, perhaps surprisingly, that researchers who are primarily statisticians are also prone to misuse and misinterpret p-values thus resulting in similar errors. In particular, we show that statisticians tend to interpret evidence dichotomously based on whether or not a p-value crosses the conventional 0.05 threshold for statistical significance. We discuss implications and offer recommendations.

KEYWORDS: Null hypothesis significance testing, p-value, Statistical significance, Sociology of science},
  doi       = {10.1080/01621459.2017.1289846},
  file      = {:Articles/Statistical Significance and the Dichotomization of Evidence.pdf:PDF},
  publisher = {Informa {UK} Limited},
}

@Article{Woltman2012,
  author    = {Heather Woltman and Andrea Feldstain and J. Christine MacKay and Meredith Rocchi},
  title     = {An introduction to hierarchical linear modeling},
  journal   = {Tutorials in Quantitative Methods for Psychology},
  year      = {2012},
  volume    = {8},
  number    = {1},
  pages     = {52--69},
  month     = {feb},
  abstract  = {This tutorial aims to introduce Hierarchical Linear Modeling (HLM). A simple explanation of HLM is provided that describes when to use this statistical technique and identifies key factors to consider before conducting this analysis. The first section of the tutorial defines HLM, clarifies its purpose, and states its advantages. The second section explains the mathematical theory, equations, and conditions underlying HLM. HLM hypothesis testing is performed in the third section. Finally, the fourth section provides a practical example of running HLM, with which readers can follow along. Throughout this tutorial, emphasis is placed on providing a straightforward overview of the basic principles of HLM.},
  doi       = {10.20982/tqmp.08.1.p052},
  file      = {:D\:/Github/Informs/Articles/p052.pdf:PDF;:C\:/Users/cjdua/Downloads/p052.zip:zip},
  publisher = {The Quantitative Methods for Psychology},
}

@Article{Song2012,
  author    = {Xin-Yuan Song and Sik-Yum Lee},
  title     = {A tutorial on the Bayesian approach for analyzing structural equation models},
  journal   = {Journal of Mathematical Psychology},
  year      = {2012},
  volume    = {56},
  number    = {3},
  pages     = {135--148},
  month     = {jun},
  abstract  = {In this paper, we provide a tutorial exposition on the Bayesian approach in analyzing structural equation models (SEMs). SEMs, which can be regarded as regression models with observed and latent variables, have been widely applied to substantive research. However, the classical methods and most commercial software in this area are based on the covariance structure approach, which would encounter serious difficulties when dealing with complicated models and/or data structures. In contrast, the Bayesian approach has much more flexibility in handling complex situations. We give a brief introduction to SEMs and a detailed description of how to apply the Bayesian approach to this kind of model. Advantages of the Bayesian approach are discussed, and results obtained from a simulation study are provided for illustration. The intended audience is statisticians/methodologists who either know about SEMs or simple Bayesian statistics, and Ph.D. students in statistics, psychometrics, or mathematical psychology.},
  doi       = {10.1016/j.jmp.2012.02.001},
  file      = {:D\:/Github/Informs/Articles/Tutorial_Bayesian_SEM.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{jones2018network,
  author    = {Jones, Payton J and Mair, Patrick and Riemann, Bradley C and Mugno, Beth L and McNally, Richard J},
  title     = {A network perspective on comorbid depression in adolescents with obsessive-compulsive disorder},
  journal   = {Journal of anxiety disorders},
  year      = {2018},
  volume    = {53},
  pages     = {1--8},
  file      = {:Articles/A Network Perspective on Comorbid Depression.pdf:PDF},
  publisher = {Elsevier},
}

@Article{Chao2017,
  author        = {Yi-Sheng Chao and Hau-tieng Wu and Marco Scutari and Tai-Shen Chen and Chao-Jung Wu and Madeleine Durand and Antoine Boivin},
  title         = {A network perspective on patient experiences and health status: the Medical Expenditure Panel Survey 2004 to 2011},
  journal       = {{BMC} Health Services Research},
  year          = {2017},
  volume        = {17},
  number        = {1},
  month         = {aug},
  __markedentry = {[cjdua:3]},
  doi           = {10.1186/s12913-017-2496-5},
  file          = {:Articles/10.1186.s12913-017-2496-5.pdf:PDF},
  publisher     = {Springer Nature},
}

@Article{McNally2017,
  author    = {R. J. McNally and P. Mair and B. L. Mugno and B. C. Riemann},
  title     = {Co-morbid obsessive{\textendash}compulsive disorder and depression: a Bayesian network approach},
  journal   = {Psychological Medicine},
  year      = {2017},
  volume    = {47},
  number    = {07},
  pages     = {1204--1214},
  month     = {jan},
  doi       = {10.1017/s0033291716003287},
  file      = {:Articles/McNally-Mair-Mugno-Riemann-in-press-Psychological-Medicine.pdf:PDF},
  publisher = {Cambridge University Press ({CUP})},
}

@Article{liu2018bus,
  author    = {Liu, Yi and Jia, Yuanhua and Feng, Xuesong and Wu, Jiang},
  title     = {Bus Route Design with a Bayesian Network Analysis of Bus Service Revenues},
  journal   = {Mathematical Problems in Engineering},
  year      = {2018},
  volume    = {2018},
  file      = {:Articles/2018. Bus Route.pdf:PDF},
  publisher = {Hindawi},
}

@Article{Deng2014,
  author    = {Li Deng},
  title     = {Deep Learning: Methods and Applications},
  journal   = {Foundations and Trends{\textregistered} in Signal Processing},
  year      = {2014},
  volume    = {7},
  number    = {3-4},
  pages     = {197--387},
  doi       = {10.1561/2000000039},
  file      = {:Articles/9781601988157-summary.pdf:PDF},
  publisher = {Now Publishers},
}

@Article{team2015stan,
  author  = {Team, Stan Developers},
  title   = {Stan Modeling Language: User’s Guide and Reference Manual},
  journal = {Version 2.12},
  year    = {2015},
}

@Article{Overstall2018,
  author      = {Antony M. Overstall and James M. McGree},
  title       = {Bayesian design of experiments for intractable likelihood models using coupled auxiliary models and multivariate emulation},
  abstract    = {A Bayesian design is given by maximising the expected utility over the design space. The utility is chosen to represent the aim of the experiment and its expectation is taken with respect to all unknowns: responses, parameters and/or models. Although straightforward in principle, there are several challenges to finding Bayesian designs in practice. Firstly, the expected utility is rarely available in closed form and requires approximation. Secondly, the expected utility needs to be maximised over a, potentially, high-dimensional design space. In the case of intractable likelihood models, these problems are compounded by the fact that the likelihood function, whose evaluation is required to approximate the expected utility, is not available in closed form. A strategy is proposed to find Bayesian designs for intractable likelihood models. It relies on the development of new methodology involving auxiliary modelling to approximate the expected utility, under an intractable likelihood model, applied with the latest approaches to maximising approximated expected utilities.},
  date        = {2018-03-19},
  eprint      = {1803.07018v1},
  eprintclass = {stat.ME},
  eprinttype  = {arXiv},
  file        = {:Articles/2018.arXiv.1803.07018.pdf:PDF},
  keywords    = {stat.ME},
}

@Article{Lakens2017,
  author  = {Lakens, D and Adolfi, FG and Albers, CJ and Anvari, F and Apps, MAJ and Argamon, SE and Zwaan, RA},
  title   = {Justify your alpha: A response to “Redefine statistical significance”},
  journal = {Retrieved from psyarxiv. com/9s3y6},
  year    = {2017},
  file    = {:D\:/Dropbox/Bayes_Reading/Justify Your Alpha.pdf:PDF},
}

@InProceedings{Dash2003,
  author       = {Dash, Denver and Cooper, Gregory F},
  title        = {Model-Averaging with Discrete Bayesian Network Classifiers},
  booktitle    = {Proc. 9th Int. Workshop Artif. Intell. Statist.},
  year         = {2003},
  pages        = {38--45},
  organization = {Citeseer},
  file         = {:C\:/Users/cjdua/Documents/download.pdf:PDF},
}

@Article{Amrhein2017,
  author    = {Valentin Amrhein and Sander Greenland},
  title     = {Remove, rather than redefine, statistical significance},
  journal   = {Nature Human Behaviour},
  year      = {2017},
  volume    = {2},
  number    = {1},
  pages     = {4--4},
  month     = {sep},
  doi       = {10.1038/s41562-017-0224-0},
  file      = {:Articles/2017.Nature_Human_Behaviour.pdf:PDF},
  publisher = {Springer Nature},
}

@Misc{,
  author = {{Stan Development Team}},
  title  = {shinystan: Interactive Visual and Numerical Diagnostics and Posterior Analysis for Bayesian Models.},
  year   = {2017},
  note   = {R package version 2.4.0},
  url    = {http://mc-stan.org/},
}

@Article{Williams2018,
  author    = {Daniel Williams},
  title     = {Predictive coding and thought},
  journal   = {Synthese},
  year      = {2018},
  month     = {mar},
  doi       = {10.1007/s11229-018-1768-x},
  file      = {:Articles/2018.Synthese.10.1007s11229-0181768-x.pdf:PDF},
  publisher = {Springer Nature},
}

@Article{Deaton2017,
  author    = {Angus Deaton and Nancy Cartwright},
  title     = {Understanding and misunderstanding randomized controlled trials},
  journal   = {Social Science {\&} Medicine},
  year      = {2017},
  month     = {dec},
  doi       = {10.1016/j.socscimed.2017.12.005},
  file      = {:Articles/1-s2.0-S0277953617307359-main.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Li2018,
  author    = {Shaobo Li and Yongming Wu and Yanxia Xu and Jie Hu and Jianjun Hu},
  title     = {A Bayesian Network Based Adaptability Design of Product Structures for Function Evolution},
  journal   = {Applied Sciences},
  year      = {2018},
  volume    = {8},
  number    = {4},
  pages     = {493},
  month     = {mar},
  doi       = {10.3390/app8040493},
  file      = {:Articles/applsci-08-00493.pdf:PDF},
  publisher = {{MDPI} {AG}},
}

@Article{Chiappa2018,
  author        = {Silvia Chiappa and Thomas P. S. Gillam},
  title         = {Path-Specific Counterfactual Fairness},
  __markedentry = {[cjdua:]},
  abstract      = {We consider the problem of learning fair decision systems in complex scenarios in which a sensitive attribute might affect the decision along both fair and unfair pathways. We introduce a causal approach to disregard effects along unfair pathways that simplifies and generalizes previous literature. Our method corrects observations adversely affected by the sensitive attribute, and uses these to form a decision. This avoids disregarding fair information, and does not require an often intractable computation of the path-specific effect. We leverage recent developments in deep learning and approximate inference to achieve a solution that is widely applicable to complex, non-linear scenarios.},
  date          = {2018-02-22},
  eprint        = {1802.08139v1},
  eprintclass   = {stat.ML},
  eprinttype    = {arXiv},
  file          = {online:http\://arxiv.org/pdf/1802.08139v1:PDF;:Articles/1802.08139.pdf:PDF},
  keywords      = {stat.ML},
}

@InProceedings{bareinboim2018,
  author    = {J. Zhang, E. Bareinboim},
  title     = {Fairness in Decision-Making -- The Causal Explanation Formula},
  booktitle = {Proceedings of the 32nd AAAI Conference on Artificial Intelligence},
  year      = {2018},
  file      = {:Articles/r30.pdf:PDF},
}

@Article{Chen238998,
  author    = {Gang Chen and Yaqiong Xiao and Paul A Taylor and Justin K Rajendra and Tracy Riggins and Fengji Geng and Elizabeth Redcay and Robert W Cox},
  title     = {Handling Multiplicity in Neuroimaging through Bayesian Lenses with Multilevel Modeling},
  journal   = {bioRxiv preprint},
  year      = {2017},
  month     = {dec},
  abstract  = {In neuroimaging, the multiplicity issue may sneak into data analysis through several channels, affecting
expected false positive rates (FPRs; type I errors) in diverse ways. One widely recognized aspect of multiplicity,
multiple testing, occurs when the investigator fits a separate model for each voxel in the brain. However,
multiplicity also occurs when the investigator conducts multiple comparisons within a model, tests two tails of
a t-test separately when prior information is unavailable about the directionality, and branches in the analytic
pipelines. The current practice of handling multiple testing through controlling the overall FPR in neuroimaging
under the null hypothesis significance testing (NHST) paradigm excessively penalizes the statistical power with
inflated type II errors. More fundamentally, the adoption of dichotomous decisions through sharp thresholding
under NHST may not be appropriate when the null hypothesis itself is not pragmatically relevant because the
effect of interest takes a continuum instead of discrete values and is not expected to be null in most brain regions.
When the noise inundates the signal, two different types of error are more relevant than the concept of FPR:
incorrect sign (type S) and incorrect magnitude (type M).
In light of these considerations, we introduce a different strategy using Bayesian hierarchical modeling (BHM)
to achieve two goals: 1) improving modeling efficiency via one integrative (instead of many separate) model and
dissolving the multiple testing issue, and 2) turning the focus of conventional NHST on FPR into quality control
by calibrating type S errors while maintaining a reasonable level of inference efficiency. The performance and
validity of this approach are demonstrated through an application at the region of interest (ROI) level, with all
the regions on an equal footing: unlike the current approaches under NHST, small regions are not disadvantaged
simply because of their physical size. In addition, compared to the massively univariate approach, BHM may
simultaneously achieve increased spatial specificity and inference efficiency. The benefits of BHM are illustrated in
model performance and quality checking using an experimental dataset. In addition, BHM offers an alternative,
confirmatory, or complementary approach to the conventional whole brain analysis under NHST, and promotes
results reporting in totality and transparency. The methodology also avoids sharp and arbitrary thresholding in
the p-value funnel to which the multidimensional data are reduced. The modeling approach with its auxiliary
tools will be available as part of the AFNI suite for general use.},
  doi       = {10.1101/238998},
  file      = {:Articles/238998.full.pdf:PDF},
  publisher = {Cold Spring Harbor Laboratory},
}

@Article{Romeijn2018,
  author    = {Jan-Willem Romeijn and Jon Williamson},
  title     = {Intervention and Identifiability in Latent Variable Modelling},
  journal   = {Minds and Machines},
  year      = {2018},
  month     = {mar},
  doi       = {10.1007/s11023-018-9460-y},
  file      = {:Articles/10.1007%2Fs11023-018-9460-y.pdf:PDF},
  publisher = {Springer Nature},
}

@Article{Hoffman2014,
  author        = {Hoffman, Matthew D and Gelman, Andrew},
  title         = {The No-U-turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo.},
  journal       = {Journal of Machine Learning Research},
  year          = {2014},
  volume        = {15},
  number        = {1},
  pages         = {1593--1623},
  __markedentry = {[cjdua:6]},
}

@Comment{jabref-meta: databaseType:bibtex;}
